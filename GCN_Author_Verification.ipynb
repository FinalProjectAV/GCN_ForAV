{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "12f52e56",
      "metadata": {
        "id": "12f52e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea8df96-9950-4597-b00e-c023482b0e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Importing nltk and download all packages of nltk\n",
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0f350e2e",
      "metadata": {
        "id": "0f350e2e"
      },
      "outputs": [],
      "source": [
        "#Importing all neccessary packages\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from itertools import combinations\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import unicodedata\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting the notebook with the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tJd3uoq8miQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc7e8fe-8266-4001-abb4-a619218cc8d1"
      },
      "id": "tJd3uoq8miQK",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload a folder to you drive name as 'Author' which will have two more folders name as fake which will have data \n",
        "#Which are not written by the author and a folder named as author which will have data which is written by\n",
        "#the author\n",
        "\n",
        "#Getting the main directory from the google drive\n",
        "Main_Directory = \"/content/drive/MyDrive/jen/DataSet\"\n",
        "#Creating a dataframe having text and label\n",
        "Author_Dataframe = pd.DataFrame(columns=['data','class'])\n",
        "#Geting folders name in main directory which is fake and original\n",
        "List_Of_Folder = os.listdir(Main_Directory)\n",
        "label=0\n",
        "#Loop on sub folders in main directory\n",
        "for Sub_Folder in List_Of_Folder:\n",
        "  #Getting the sub directory of each folder\n",
        "  Sub_directory = Main_Directory + \"/\" + Sub_Folder\n",
        "  #Gets the list of file in each subfolder\n",
        "  filenames = os.listdir(Sub_directory) \n",
        "  #If folder is fake it labels it 0 and if not than label it 1\n",
        "  if Sub_Folder=='fake':\n",
        "    label=0\n",
        "  else:\n",
        "    label=1\n",
        "  #Reading each file one by one in the folders of fake and original\n",
        "  for eachfile in filenames:\n",
        "    #Getting file directory\n",
        "    finaldirectory = Sub_directory + \"/\" + eachfile\n",
        "    #Opening each file one by one\n",
        "    currentfile = open(finaldirectory, 'r')\n",
        "    #Reading each file one by one\n",
        "    File_content = currentfile.read()\n",
        "    #Saving the file content and label define earlier in a dataframe\n",
        "    temp = pd.DataFrame({\"data\":[File_content],\"Book Name\":eachfile,\n",
        "                    \"class\":[label]})\n",
        "    #Adding up dataframe to original     \n",
        "    Author_Dataframe = Author_Dataframe.append(temp)"
      ],
      "metadata": {
        "id": "8OgenFARmoW-"
      },
      "id": "8OgenFARmoW-",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stopword_removal_and_special_tokens takes list of tokens and list of stopwords and then then check if the token is in stopword then it removes from it\n",
        "#It also remove different type of characters from the list of tokens that is given as input like (- ' , . \" : @ { } [ ] ? etc) \n",
        "#and it also remove the punctuation token from it after removing all these tokens it returns the remaining tokens\n",
        "def Stopword_removal_and_special_tokens(Input_Tokens, stopwords):\n",
        "    Clean_Input = []\n",
        "    for token in Input_Tokens:\n",
        "        if (token not in stopwords) and (token not in [\"\\n\",\"\",\" \",\".\",\",\",\";\",\"&\",\"'s\", \"’\",\":\", \"?\", \"!\",\"(\",\")\",\"”\",\"“\",\\\n",
        "            \"'\",\"'m\",\"'no\",\"*\",\"--\",\"...\",\"[\",\"]\",\"—\", \"@\"]):\n",
        "            Clean_Input.append(token)\n",
        "    return Clean_Input\n",
        "\n",
        "#Resetting the indexes\n",
        "Author_Dataframe=Author_Dataframe.reset_index(drop=True) \n",
        "#Finding stopwords using nltk\n",
        "stopwords = list(set(nltk.corpus.stopwords.words(\"russian\"))) \n",
        "#Tokenizing the each row of data frame and removing the special characters and stopwords from the tokens list\n",
        "Author_Dataframe[\"data\"] = Author_Dataframe[\"data\"].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: Stopword_removal_and_special_tokens(x, stopwords))\n",
        "\n",
        "#Loop to remove numbers and punctuation from data and converting it into lowercase\n",
        "for i in range(len(Author_Dataframe[\"data\"])):\n",
        "    #Getting Each row from the dataframe\n",
        "    Input_Tokens = Author_Dataframe[\"data\"][i]\n",
        "    #List to save clean tokens\n",
        "    Clean_Tokens = []\n",
        "    #Loop to check if tokens are puntuation or not and append it into clean tokens after converting it into lowercase\n",
        "    for token in Input_Tokens:\n",
        "        word = re.sub(r'[^\\w\\s]', ' ', token)\n",
        "        if word != '':\n",
        "            Clean_Tokens.append(word.lower())\n",
        "    #Saving clean tokens in the dataframe\n",
        "    Author_Dataframe[\"data\"][i] = Clean_Tokens\n",
        "    #Getting Each row from the dataframe\n",
        "    Input_Tokens = Author_Dataframe[\"data\"][i]\n",
        "    #List to without numbers\n",
        "    Remove_digits = []\n",
        "    #Loop to check if tokens are numbers or not and append it into remove digits if its not a number\n",
        "    for token in Input_Tokens:\n",
        "        if token.isdigit():\n",
        "            continue\n",
        "        else:\n",
        "            Remove_digits.append(token)\n",
        "    #Saving tokens without numbers in the dataframe\n",
        "    Author_Dataframe[\"data\"][i] = Remove_digits\n",
        "    #Removing white spaces tokens from list\n",
        "    if(\" \" in Author_Dataframe[\"data\"][i]):\n",
        "        Author_Dataframe[\"data\"][i].remove(\" \")\n",
        "    #Removing empty tokens from list\n",
        "    if(\"\" in Author_Dataframe[\"data\"][i]):\n",
        "        Author_Dataframe[\"data\"][i].remove(\"\")\n",
        "print(Author_Dataframe)"
      ],
      "metadata": {
        "id": "qYv65YVVrQBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27d02b9-c937-4224-ac2a-96e7e1646da2"
      },
      "id": "qYv65YVVrQBL",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 data class  \\\n",
            "0   [без, огня, пароход, идет, час, виден, город, ...     0   \n",
            "1   [будни, i, плотник, лактион, никитич, вырезыва...     0   \n",
            "2   [в, родных, местах, i, ссыльный, поселенец, ен...     0   \n",
            "3   [жажда, ветерок, степи, налетал, капризными, п...     0   \n",
            "4   [послушайте, господин, дастих, озабоченно, ска...     0   \n",
            "5   [мелеховский, двор, самом, краю, хутора, ворот...     0   \n",
            "6   [лазоревая, степь, над, доном, облысевшем, сол...     1   \n",
            "7   [ка, для, деда, ласковую, минуту, постреленыш,...     1   \n",
            "8   [валентин, осипов, писатель, властьоткрытия, а...     1   \n",
            "9   [регибы, собственно, применялось, допросах, об...     1   \n",
            "10  [ком, семякине, шестовой, а, зря, посажены, не...     1   \n",
            "11  [в, округ, приезжал, областной, продовольствен...     1   \n",
            "12  [испытание, случай, жизни, одного, уезда, двин...     1   \n",
            "13  [пастух, i, из, степи, бурой, выжженной, солнц...     1   \n",
            "14  [коловерть, i, на, закате, солнца, вернулся, с...     1   \n",
            "15  [часть, первая, i, вдоль, дона, самого, моря, ...     1   \n",
            "\n",
            "                  Book Name  \n",
            "0                    f1.txt  \n",
            "1                    f2.txt  \n",
            "2                    f3.txt  \n",
            "3                    f4.txt  \n",
            "4                    f5.txt  \n",
            "5   quiet flows the don.txt  \n",
            "6                    o1.txt  \n",
            "7                    o2.txt  \n",
            "8                    o3.txt  \n",
            "9                    o4.txt  \n",
            "10                   o5.txt  \n",
            "11                   o6.txt  \n",
            "12                   o7.txt  \n",
            "13                   o8.txt  \n",
            "14                  o12.txt  \n",
            "15                  o13.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5b13c4a1",
      "metadata": {
        "id": "5b13c4a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff58f14f-f26e-47cf-e10b-7550982a41f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tf-idf Calculations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Co-Occurences Calculations\n"
          ]
        }
      ],
      "source": [
        "def Dumming_Variable(Document):\n",
        "    return Document\n",
        "print(\"Tf-idf Calculations\")\n",
        "#Tf-idf Calculation using the data features\n",
        "Tfidf_Author_Vector = TfidfVectorizer(input=\"content\", max_features=None, tokenizer=Dumming_Variable, preprocessor=Dumming_Variable)\n",
        "Tfidf_Author_Vector.fit(Author_Dataframe[\"data\"])\n",
        "Author_Data_Tfidf = Tfidf_Author_Vector.transform(Author_Dataframe[\"data\"])\n",
        "#Converting Tfidf of the Author_Data into array \n",
        "Author_Data_Tfidf = Author_Data_Tfidf.toarray() \n",
        "#Getting vocabulary of the Author Data\n",
        "Author_Data_Vocabulary = Tfidf_Author_Vector.get_feature_names() \n",
        "#Saving the vocabulary we just created into np array\n",
        "Author_Data_Vocabulary = np.array(Author_Data_Vocabulary) \n",
        "#Creating dataframe for the Tfidf using the vocabulary\n",
        "Author_Data_Tfidf = pd.DataFrame(Author_Data_Tfidf,columns=Author_Data_Vocabulary) \n",
        "\n",
        "\n",
        "#Creating word to word co-occurencces of the each words \n",
        "print(\"Co-Occurences Calculations\")\n",
        "#Getting feature name from the vocabulary\n",
        "Features_Names = Author_Data_Vocabulary\n",
        "#Max Window Size for the model\n",
        "Window_Size=10\n",
        "#Getting Word to word occurence\n",
        "Word_Word_Occur  = OrderedDict((feature, 0) for feature in Features_Names)\n",
        "Word_To_Word = OrderedDict( (feature,i) for i,feature in enumerate(Features_Names) )\n",
        "#Getting Word to word co-occurence\n",
        "Word_Word_Co_Occur = np.zeros( (len(Features_Names),len(Features_Names)) ,dtype=np.int8)\n",
        "#Current window number\n",
        "Windows_Number = 0; \n",
        "for i in Author_Dataframe[\"data\"]:\n",
        "    for j in range(len(i)-Window_Size):\n",
        "        Windows_Number += 1\n",
        "        content = set(i[j:(j+Window_Size)])\n",
        "        #Calculating Co-occurences of eac words\n",
        "        for token in content:\n",
        "            Word_Word_Occur[token] += 1\n",
        "        for First_Word,Second_Word in combinations(content,2):\n",
        "            First_Word_Index = Word_To_Word[First_Word]\n",
        "            Second_Word_Index = Word_To_Word[Second_Word]\n",
        "            Word_Word_Co_Occur[First_Word_Index][Second_Word_Index] += 1\n",
        "            Word_Word_Co_Occur[Second_Word_Index][First_Word_Index] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "834655a2",
      "metadata": {
        "id": "834655a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df6e067-07f1-4fae-f1cf-6c876a3b9e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pointwise Mutual Information Calculations\n"
          ]
        }
      ],
      "source": [
        "print(\"Pointwise Mutual Information Calculations\")\n",
        "#Converting that word to word co-ocurrence into Pointwise mutual information\n",
        "Pointwise_Mutual_Info_IJ = pd.DataFrame(Word_Word_Co_Occur, index = Features_Names,columns=Features_Names)/Windows_Number\n",
        "#Converting that word to word ocurrence into Pointwise mutual information\n",
        "Pointwise_Mutual_Info_I = pd.Series(Word_Word_Occur, index=Word_Word_Occur.keys())/Windows_Number\n",
        "#Calculations for the Pointwise Mutual information \n",
        "for col in Pointwise_Mutual_Info_IJ.columns:\n",
        "    Pointwise_Mutual_Info_IJ[col] = Pointwise_Mutual_Info_IJ[col]/Pointwise_Mutual_Info_I[col]\n",
        "for row in Pointwise_Mutual_Info_IJ.index:\n",
        "    Pointwise_Mutual_Info_IJ.loc[row,:] = Pointwise_Mutual_Info_IJ.loc[row,:]/Pointwise_Mutual_Info_I[row]\n",
        "#Adding 1e-9(0.000000001) to the Pointwise Mutual information to the values if any value is zero\n",
        "Pointwise_Mutual_Info_IJ = Pointwise_Mutual_Info_IJ + 1E-9\n",
        "#Replacing NAN values in the array with 1e-9\n",
        "Pointwise_Mutual_Info_IJ = Pointwise_Mutual_Info_IJ.replace(np.nan,1E-9 , regex=True)\n",
        "#Replacing Negative values  with 1e-9\n",
        "Pointwise_Mutual_Info_IJ[Pointwise_Mutual_Info_IJ < 0] = 1E-9 \n",
        "for col in Pointwise_Mutual_Info_IJ.columns:\n",
        "    Pointwise_Mutual_Info_IJ[col] = Pointwise_Mutual_Info_IJ[col].apply(lambda x: math.log(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "Pointwise_Mutual_Info_IJ=pickle.load( open( '/content/drive/MyDrive/jen/Pointwise_Mutual_Info_IJ11.P', \"rb\" ) )"
      ],
      "metadata": {
        "id": "B_if7vAEeo4O"
      },
      "id": "B_if7vAEeo4O",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pickle.dump(  Pointwise_Mutual_Info_IJ, open( '/content/drive/MyDrive/jen/Pointwise_Mutual_Info_IJ11.P', \"wb\" ) )"
      ],
      "metadata": {
        "id": "terGeM8fZPRb"
      },
      "id": "terGeM8fZPRb",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the tfidf\n",
        "print(Author_Data_Tfidf) "
      ],
      "metadata": {
        "id": "wxdcxmsVSq_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a96f72-c2bc-487b-e416-043a3bf4bcd1"
      },
      "id": "wxdcxmsVSq_Y",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          репрессии        10        14        18         2  \\\n",
            "0   0.182598  0.223211     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1   0.401738  0.161224     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "2   0.171169  0.173036     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "3   0.199222  0.083791     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "4   0.031564  0.000000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "5   0.797966  0.096663     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "6   0.052656  0.276140     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "7   0.029007  0.307654     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "8   0.770756  0.003181     0.004709  0.000000  0.000000  0.000000  0.000000   \n",
            "9   0.458840  0.001986     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "10  0.323605  0.001769     0.000000  0.005238  0.005238  0.005238  0.015714   \n",
            "11  0.012021  0.152992     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "12  0.248823  0.175939     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "13  0.071845  0.135468     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "14  0.068049  0.369366     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "15  0.070747  0.284063     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "         2 1        21        22  ...  ячменного  ячменной    ячмень  \\\n",
            "0   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "1   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "2   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "3   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "4   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "5   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "6   0.000000  0.000000  0.000000  ...   0.000000  0.009186  0.000000   \n",
            "7   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "8   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "9   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "10  0.005238  0.005238  0.005238  ...   0.000000  0.000000  0.000000   \n",
            "11  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.029413   \n",
            "12  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.028993   \n",
            "13  0.000000  0.000000  0.000000  ...   0.025067  0.000000  0.009767   \n",
            "14  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "15  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
            "\n",
            "         яша      яша       яшей      яшку     ящика    ящиках     ящики  \n",
            "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "8   0.000000  0.000000  0.000000  0.000000  0.004101  0.000000  0.000000  \n",
            "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "13  0.021830  0.012533  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "14  0.000000  0.000000  0.000000  0.000000  0.010946  0.012569  0.000000  \n",
            "15  0.013819  0.000000  0.015868  0.015868  0.000000  0.000000  0.015868  \n",
            "\n",
            "[16 rows x 32042 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing PMI that is calculated above \n",
        "print(Pointwise_Mutual_Info_IJ)"
      ],
      "metadata": {
        "id": "KvXiG0aPhZiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d50fce-ee41-413e-fd18-890908c42123"
      },
      "id": "KvXiG0aPhZiO",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     репрессии         10         14  \\\n",
            "            -20.723266 -20.723266     1.526545   1.526545 -20.723266   \n",
            "            -20.723266 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "  репрессии   1.526545 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            " 10           1.526545 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            " 14         -20.723266 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "...                ...        ...          ...        ...        ...   \n",
            "ячейках     -20.723266 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "ячейки        0.607401 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "ячменной    -20.723266 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "ячмень      -20.723266 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "ящика       -20.723266 -20.723266   -20.723266 -20.723266 -20.723266   \n",
            "\n",
            "                    18          2        2 1         21         22  ...  \\\n",
            "            -20.723266   0.938759 -20.723266   1.631906   1.526545  ...   \n",
            "            -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "  репрессии -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            " 10         -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            " 14         -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "...                ...        ...        ...        ...        ...  ...   \n",
            "ячейках     -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "ячейки      -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "ячменной    -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "ячмень      -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "ящика       -20.723266 -20.723266 -20.723266 -20.723266 -20.723266  ...   \n",
            "\n",
            "                 ясный      ясным     ясными    ястреба      ячеек    ячейках  \\\n",
            "            -20.723266 -20.723266 -20.723266 -20.723266  -0.447536 -20.723266   \n",
            "            -20.723266   2.467734 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "  репрессии -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            " 10         -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            " 14         -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "...                ...        ...        ...        ...        ...        ...   \n",
            "ячейках     -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "ячейки      -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "ячменной    -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "ячмень      -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "ящика       -20.723266 -20.723266 -20.723266 -20.723266 -20.723266 -20.723266   \n",
            "\n",
            "                ячейки   ячменной     ячмень      ящика  \n",
            "              0.607401 -20.723266 -20.723266 -20.723266  \n",
            "            -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "  репрессии -20.723266 -20.723266 -20.723266 -20.723266  \n",
            " 10         -20.723266 -20.723266 -20.723266 -20.723266  \n",
            " 14         -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "...                ...        ...        ...        ...  \n",
            "ячейках     -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "ячейки      -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "ячменной    -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "ячмень      -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "ящика       -20.723266 -20.723266 -20.723266 -20.723266  \n",
            "\n",
            "[27886 rows x 27886 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4172051b",
      "metadata": {
        "id": "4172051b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "2b4fd5f2-4e39-47a7-a7b9-70a4bd95392f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Graph where Number of document is 16 and word nodes are 32042\n",
            "Adding document nodes to the graph\n",
            "Adding word nodes to the graph\n",
            "Creating document word edges\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:06<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating word-word edges\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 237368/388800555 [00:03<1:28:01, 73563.88it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b6193cbf39bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcoloumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoloumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mFirst_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSecond_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoloumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoloumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoloumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPointwise_Mutual_Info_IJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFirst_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSecond_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mWord_Word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFirst_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSecond_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPointwise_Mutual_Info_IJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFirst_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSecond_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3579\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3580\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3581\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3582\u001b[0m             \u001b[0;31m# IntervalTree has no get_loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \"\"\"\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;31m# error: Decorated property not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Building the graph using nx python library\n",
        "print(\"Building Graph where Number of document is\",len(Author_Data_Tfidf.index),\"and word nodes are\",len(Author_Data_Vocabulary))\n",
        "Model_Graph = nx.Graph()\n",
        "#First all we add document nodes to the graph we created\n",
        "print(\"Adding document nodes to the graph\")\n",
        "Model_Graph.add_nodes_from(Author_Data_Tfidf.index) \n",
        "#Now we add word nodes to the graph\n",
        "print(\"Adding word nodes to the graph\")\n",
        "Model_Graph.add_nodes_from(Author_Data_Vocabulary) \n",
        "\n",
        "#Nodes are adding into the graph now we have to created edges\n",
        "#First create document word edges for the graph\n",
        "print(\"Creating document word edges\")\n",
        "Doc_Word = [(doc,w,{\"weight\":Author_Data_Tfidf.loc[doc,w]}) for doc in tqdm(Author_Data_Tfidf.index, total=len(Author_Data_Tfidf.index)) for w in Author_Data_Tfidf.columns]\n",
        "#Now create word-word edges in the graph\n",
        "print(\"Creating word-word edges\")\n",
        "\n",
        "#Now construct the list having tuple which save the two words \n",
        "#And thier weight on each index wieght here is the PMI value calculated earlier\n",
        "#Construct a list of word-word edges having a certain weight which means each index of list will have two words and a weight\n",
        "Word_Word = []\n",
        "coloumn = list(Pointwise_Mutual_Info_IJ.columns);\n",
        "coloumn = [str(word) for word in coloumn]\n",
        "for First_word, Second_word in tqdm(combinations(coloumn, 2), total=int(math.factorial(len(coloumn))/(math.factorial(2)*math.factorial(len(coloumn)-2)))):\n",
        "    if (Pointwise_Mutual_Info_IJ.loc[First_word,Second_word] > 0):\n",
        "        Word_Word.append((First_word,Second_word,{\"weight\":Pointwise_Mutual_Info_IJ.loc[First_word,Second_word]}))\n",
        "\n",
        "print(\"Adding document word, word word edges graph\")\n",
        "#Adding Edges to the graph\n",
        "Model_Graph.add_edges_from(Doc_Word)\n",
        "Model_Graph.add_edges_from(Word_Word)\n",
        "print(\"Graph Is Constructed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Graph = pickle.load( open( '/content/drive/MyDrive/jen/Model_Graph.P', \"rb\" ) )"
      ],
      "metadata": {
        "id": "s71f8Lujf-NP"
      },
      "id": "s71f8Lujf-NP",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pickle.dump(  Model_Graph, open( '/content/drive/MyDrive/jen/Model_Graph.P', \"wb\" ) )"
      ],
      "metadata": {
        "id": "SCdZZkvEcwSD"
      },
      "id": "SCdZZkvEcwSD",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "3aae1ef1",
      "metadata": {
        "id": "3aae1ef1"
      },
      "outputs": [],
      "source": [
        "#318 number of neurons in first hidden layer of the GCN Model\n",
        "Size_Of_First_Hidden_Layer = 318 \n",
        "#126 number of neurons in second hidden layer of the GCN Model\n",
        "Size_Of_Second_Hidden_Layer = 126 \n",
        "\n",
        "#GCN_For_Author_Data is model that have 2 hidden layer architecture for classification of book author\n",
        "#Models first hidden layer has 318 neurons and models second hidden layer consist of the 126 neurons\n",
        "#This model will predict wheather the given text is original written by Author or not with we \n",
        "#consider the label 0 if its not written by Author and label 1 it's written by Author \n",
        "class GCN_For_Author_Data(nn.Module):\n",
        "    #Init function initialize initial weights to the first and second hidden layer of the gcn model and sets the variables for the input layer with the biases\n",
        "    #Features_Matrix are the total number of features in the data\n",
        "    def __init__(self, Features_Matrix, Features_Adjancy_Matrix, bias=True): \n",
        "        #Calling the Super class of GCN model to initialize the model\n",
        "        super(GCN_For_Author_Data, self).__init__()   \n",
        "        #Converting the given features into a type of tensor object                                  \n",
        "        self.Features_Adjancy_Matrix = torch.tensor(Features_Adjancy_Matrix, requires_grad=False).float()\n",
        "        #Initializing the first layer weights with the features name\n",
        "        self.input_layer_weight = nn.parameter.Parameter(torch.FloatTensor(Features_Matrix, Size_Of_First_Hidden_Layer))\n",
        "        #Initializing the initial variables using the wieghts we just initialize\n",
        "        input_layer_variables = 2./(self.input_layer_weight.size(1)+self.input_layer_weight.size(0))\n",
        "        self.input_layer_weight.data.normal_(0,input_layer_variables)\n",
        "        #Initializing the second layer weights with the hidden layers \n",
        "        self.input_second_layer_weight_ = nn.parameter.Parameter(torch.FloatTensor(Size_Of_First_Hidden_Layer, Size_Of_Second_Hidden_Layer))\n",
        "        #Initializing the second layer variables using the second layer wieghts we just initialize\n",
        "        input_second_layer_variables = 2./(self.input_second_layer_weight_.size(1)+self.input_second_layer_weight_.size(0))\n",
        "        self.input_second_layer_weight_.data.normal_(0,input_second_layer_variables)\n",
        "        #Adding the biases to the wieghts\n",
        "        if bias:\n",
        "            #Initialize first layer bias\n",
        "            self.input_layer_bias = nn.parameter.Parameter(torch.FloatTensor(Size_Of_First_Hidden_Layer))\n",
        "            self.input_layer_bias.data.normal_(0,input_layer_variables)\n",
        "            #Initialize second layer bias\n",
        "            self.input_second_layer_bias = nn.parameter.Parameter(torch.FloatTensor(Size_Of_Second_Hidden_Layer))\n",
        "            self.input_second_layer_bias.data.normal_(0,input_second_layer_variables)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "        self.fc1 = nn.Linear(Size_Of_Second_Hidden_Layer,2)\n",
        "        \n",
        "    # Its a Feed forward GCN model and this functon shows the forward pass of the model\n",
        "    def forward(self, Initial_Value): \n",
        "        Initial_Value = torch.mm(Initial_Value, self.input_layer_weight)\n",
        "        if self.input_layer_bias is not None:\n",
        "            Initial_Value = (Initial_Value + self.input_layer_bias)\n",
        "        Initial_Value = F.relu(torch.mm(self.Features_Adjancy_Matrix, Initial_Value))\n",
        "        Initial_Value = torch.mm(Initial_Value, self.input_second_layer_weight_)\n",
        "        if self.input_second_layer_bias is not None:\n",
        "            Initial_Value = (Initial_Value + self.input_second_layer_bias)\n",
        "        Initial_Value = F.relu(torch.mm(self.Features_Adjancy_Matrix, Initial_Value))\n",
        "        return self.fc1(Initial_Value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "95b47afd",
      "metadata": {
        "id": "95b47afd"
      },
      "outputs": [],
      "source": [
        "#Ratio used to split training data into two equal chunks one for training purpose other for testing purpose\n",
        "Ratio_To_Split_Data=0.5 \n",
        "\n",
        "#Creating_Input_Matrix helps to create the indentity matrix which is used as a input in GCN Model\n",
        "def Creating_Input_Matrix():\n",
        "    #Creating adjacency matrix\n",
        "    Adjacency_Matrix = nx.to_numpy_array(Model_Graph, weight=\"weight\");\n",
        "    Adjacency_Matrix = Adjacency_Matrix + np.eye(Model_Graph.number_of_nodes())\n",
        "    #Creating degree matrix\n",
        "    Degree = []\n",
        "    for deg in Model_Graph.degree(weight=None):\n",
        "        if deg != 0:\n",
        "            Degree.append(deg[1]**(-0.5))\n",
        "        else:\n",
        "            Degree.append(0)\n",
        "\n",
        "    Degree = np.diag(Degree)\n",
        "    #Creating identity matrix which have the features\n",
        "    Iden_Matrix = np.eye(Model_Graph.number_of_nodes())\n",
        "    #Transformed adjacency matrix\n",
        "    Transformed_Adjacency_Matrix = Degree@Adjacency_Matrix@Degree \n",
        "    #Input for GCN model\n",
        "    GCN_Input = Iden_Matrix \n",
        "    #Splitting the train data\n",
        "    Test_Data = []\n",
        "    for dataclass in Author_Dataframe[\"class\"].unique():\n",
        "        Temporary = Author_Dataframe[Author_Dataframe[\"class\"] == dataclass]        \n",
        "        Test_Data.extend(list(np.random.choice(Temporary.index, size=round(Ratio_To_Split_Data*len(Temporary)), replace=False)))\n",
        "    \n",
        "\n",
        "    #Select only certain labelled nodes for semi-supervised GCN\n",
        "    Train_Data = []\n",
        "    for i in range(len(Author_Dataframe)):\n",
        "        if i not in Test_Data:\n",
        "            Train_Data.append(i)\n",
        "    \n",
        "    print(\"Training Indexes : \", Train_Data)\n",
        "    print(\"Test Indexes : \", Test_Data)\n",
        "\n",
        "    #Selecting the train data and splitting labels\n",
        "    Input_Selected = GCN_Input[Train_Data]; \n",
        "    Input_Selected = torch.from_numpy(Input_Selected).float()\n",
        "    Train_Labels = [i for dataclass, i in enumerate(Author_Dataframe[\"class\"]) if dataclass in Train_Data]\n",
        "    #Selecting the test data and and splitting labels\n",
        "    Test_Data_Selected = GCN_Input[Test_Data]; \n",
        "    Test_Data_Selected = torch.from_numpy(Test_Data_Selected).float()\n",
        "    Test_Labels = [i for dataclass, i in enumerate(Author_Dataframe[\"class\"]) if dataclass not in Train_Data]\n",
        "    GCN_Input = torch.from_numpy(GCN_Input).float()\n",
        "    return GCN_Input, Iden_Matrix, Transformed_Adjacency_Matrix, Train_Data, Train_Labels, Test_Labels, Test_Data\n",
        "    \n",
        "\n",
        "#Get Accuracy takes original label and predicted labels and find the accuracy and return it\n",
        "def GetAccuracy(Predictied, Original):\n",
        "    _, labels = Predictied.max(1); \n",
        "    labels = labels.numpy()\n",
        "    labels = list(labels)\n",
        "    sumlabel = 0\n",
        "    for i in range(len(labels)):\n",
        "      if(labels[i]==Original[i]):\n",
        "        sumlabel+=1\n",
        "    return sumlabel/len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a380cc22",
      "metadata": {
        "id": "a380cc22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43737c6a-8029-45bb-dda9-bcea20a27a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Indexes :  [0, 2, 4, 6, 7, 8, 9, 11]\n",
            "Test Indexes :  [3, 5, 1, 10, 15, 14, 13, 12]\n",
            "[Epoch 1 ]: Evaluation accuracy of trained nodes: 37.500\n",
            "[Epoch 1 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 1 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
            "[Epoch 1 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 2 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 2 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 2 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 2 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 3 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 3 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 3 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 3 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 4 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 4 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 4 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 4 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 5 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 5 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 5 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 5 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 6 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 6 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 6 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 6 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 7 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 7 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 7 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 7 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 8 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 8 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 8 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 8 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 9 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 9 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 9 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 9 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 10 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 10 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 10 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 10 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 11 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 11 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 11 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 11 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 12 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 12 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 12 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 12 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 13 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 13 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 13 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 13 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 14 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 14 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 14 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 14 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 15 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 15 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 15 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 15 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 16 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 16 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 16 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 16 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 17 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 17 ]: Evaluation accuracy of test nodes: 62.500\n",
            "[Epoch 17 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 17 ]: Predicted Labels of test nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 18 ]: Evaluation accuracy of trained nodes: 62.500\n",
            "[Epoch 18 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 18 ]: Predicted Labels of trained nodes:  tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[Epoch 18 ]: Predicted Labels of test nodes:  tensor([0, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 19 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 19 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 19 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 19 ]: Predicted Labels of test nodes:  tensor([0, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 20 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 20 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 20 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 20 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 21 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 21 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 21 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 21 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 22 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 22 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 22 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 22 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 23 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 23 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 23 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 23 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 24 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 24 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 24 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 24 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 25 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 25 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 25 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 25 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 26 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 26 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 26 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 26 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 1, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 27 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 27 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 27 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 27 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 28 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 28 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 28 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 28 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 29 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 29 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 29 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 29 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 30 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 30 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 30 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 30 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 31 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 31 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 31 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 31 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 32 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 32 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 32 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 32 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 33 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 33 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 33 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 33 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 34 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 34 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 34 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 34 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 35 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 35 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 35 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 35 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 36 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 36 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 36 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 36 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 37 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 37 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 37 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 37 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 38 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 38 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 38 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 38 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 39 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 39 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 39 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 39 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 40 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 40 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 40 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 40 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 41 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 41 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 41 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 41 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 42 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 42 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 42 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 42 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 43 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 43 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 43 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 43 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 44 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 44 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 44 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 44 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 45 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 45 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 45 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 45 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 46 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 46 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 46 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 46 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 47 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 47 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 47 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 47 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 48 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 48 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 48 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 48 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 49 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 49 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 49 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 49 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 50 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 50 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 50 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 50 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 51 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 51 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 51 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 51 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 52 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 52 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 52 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 52 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 53 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 53 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 53 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 53 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 54 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 54 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 54 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 54 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 55 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 55 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 55 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 55 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 56 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 56 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 56 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 56 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 57 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 57 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 57 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 57 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 58 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 58 ]: Evaluation accuracy of test nodes: 75.000\n",
            "[Epoch 58 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 58 ]: Predicted Labels of test nodes:  tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 59 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 59 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 59 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 59 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 60 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 60 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 60 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 60 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 61 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 61 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 61 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 61 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 62 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 62 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 62 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 62 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 63 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 63 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 63 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 63 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 64 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 64 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 64 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 64 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 65 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 65 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 65 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 65 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 66 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 66 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 66 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 66 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 67 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 67 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 67 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 67 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 68 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 68 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 68 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 68 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 69 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 69 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 69 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 69 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 70 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 70 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 70 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 70 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 71 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 71 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 71 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 71 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 72 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 72 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 72 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 72 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 73 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 73 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 73 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 73 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 74 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 74 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 74 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 74 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 75 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 75 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 75 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 75 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 76 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 76 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 76 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 76 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 77 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 77 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 77 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 77 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 78 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 78 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 78 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 78 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 79 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 79 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 79 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 79 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 80 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 80 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 80 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 80 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 81 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 81 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 81 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 81 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 82 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 82 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 82 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 82 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 83 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 83 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 83 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 83 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 84 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 84 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 84 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 84 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 85 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 85 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 85 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 85 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 86 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 86 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 86 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 86 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 87 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 87 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 87 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 87 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 88 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 88 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 88 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 88 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 89 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 89 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 89 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 89 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 90 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 90 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 90 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 90 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 91 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 91 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 91 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 91 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 92 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 92 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 92 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 92 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 93 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 93 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 93 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 93 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 94 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 94 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 94 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 94 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 95 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 95 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 95 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 95 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 96 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 96 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 96 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 96 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 97 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 97 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 97 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 97 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 98 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 98 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 98 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 98 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 99 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 99 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 99 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 99 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n",
            "[Epoch 100 ]: Evaluation accuracy of trained nodes: 100.000\n",
            "[Epoch 100 ]: Evaluation accuracy of test nodes: 87.500\n",
            "[Epoch 100 ]: Predicted Labels of trained nodes:  tensor([0, 0, 0, 1, 1, 1, 1, 1])\n",
            "[Epoch 100 ]: Predicted Labels of test nodes:  tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Number of classes in the Author author prediction dataset\n",
        "Classes=2 \n",
        "#Total Number of epochs we used for the GCN Model to train\n",
        "Epochs_To_Train_Model=100 \n",
        "#We add 0.15 as the learning rate of model \n",
        "Learning_Rate=0.015 \n",
        "#Model ID\n",
        "Model_ID=0 \n",
        "\n",
        "#Fiding model input and splitting data into test and train\n",
        "GCN_Input, Iden_Matrix, Transformed_Adjacency_Matrix, Train_Data, Train_Labels, Test_Labels, Test_Data = Creating_Input_Matrix()\n",
        "#Creating the gcn model using input\n",
        "Model_Network = GCN_For_Author_Data(Iden_Matrix.shape[1], Transformed_Adjacency_Matrix)\n",
        "#Loss Function \n",
        "Model_Network_Criterion = nn.CrossEntropyLoss() \n",
        "#Optimizer \n",
        "Model_Network_Optimizer = optim.Adam(Model_Network.parameters(), lr=Learning_Rate)\n",
        "#Scheduler\n",
        "Model_Network_Scheduler = optim.lr_scheduler.MultiStepLR(Model_Network_Optimizer, milestones=[1000,2000,3000,4000,5000,6000], gamma=0.77)    \n",
        "# Training the model\n",
        "Model_Network.train() \n",
        "#Save accuracy for training set after each epochs\n",
        "Training_Accuracy = []\n",
        "#Save accuracy for test set after each epochs\n",
        "Test_Accuracy = []\n",
        "#Save loss for training set after each epochs\n",
        "Losses_Per_Epoch = []\n",
        "Predict_Output = []\n",
        "#Loop runs for the number epochs define \n",
        "for epoch in range(0, Epochs_To_Train_Model):\n",
        "    Model_Network_Optimizer.zero_grad()\n",
        "    #Predicting the output using the model on train data\n",
        "    Predicted_Output = Model_Network(GCN_Input)\n",
        "    #Finding the loss on train data\n",
        "    Network_Loss = Model_Network_Criterion(Predicted_Output[Train_Data], torch.tensor(Train_Labels).long())\n",
        "    #Append loss into lsit  \n",
        "    Losses_Per_Epoch.append(Network_Loss.item())\n",
        "    Network_Loss.backward()\n",
        "    Model_Network_Optimizer.step()\n",
        "    Model_Network.eval()\n",
        "    with torch.no_grad():\n",
        "        #Predicting Test Labels\n",
        "        Predicted_Labels = Model_Network(GCN_Input)\n",
        "        #Calculating train accuracy\n",
        "        Training_acc = GetAccuracy(Predicted_Output[Train_Data], Train_Labels); \n",
        "        #Calculating test accuracy\n",
        "        Test_acc = GetAccuracy(Predicted_Labels[Test_Data], Test_Labels)\n",
        "    #Appending training accuracy to the list   \n",
        "    Training_Accuracy.append((epoch, Training_acc)); \n",
        "    #Appending test accuracy to the list\n",
        "    Test_Accuracy.append((epoch, Test_acc))   \n",
        "    #Printing accuracy for train and test and class prediction\n",
        "    print(\"[Epoch %d ]: Evaluation accuracy of trained nodes: %.3f\" % (epoch+1, Training_acc*100))\n",
        "    print(\"[Epoch %d ]: Evaluation accuracy of test nodes: %.3f\" % (epoch+1, Test_acc*100))\n",
        "    print(\"[Epoch\",epoch+1,\"]: Predicted Labels of trained nodes: \",Predicted_Output[Train_Data].max(1)[1])\n",
        "    print(\"[Epoch\",epoch+1,\"]: Predicted Labels of test nodes: \",Predicted_Labels[Test_Data].max(1)[1])\n",
        "    Predict_Output = Predicted_Labels[Test_Data].max(1)[1]\n",
        "    print()\n",
        "    #Trainig again model to give more accurracy\n",
        "    Model_Network.train()\n",
        "    Model_Network_Scheduler.step()\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Books=[]\n",
        "Test_Outputs=Author_Dataframe.iloc[Test_Data]\n",
        "for i in Predict_Output:\n",
        "  if(int(i)==0):\n",
        "    Books.append(\"Fake\")\n",
        "  else:\n",
        "    Books.append(\"Original\")\n",
        "Test_Outputs[\"Predicted_As\"]=Books\n",
        "print(Test_Outputs[[\"Book Name\",\"Predicted_As\"]])"
      ],
      "metadata": {
        "id": "K9J5yrukGe2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb3bbef-7cc4-4901-f358-2b5a2d15e6f6"
      },
      "id": "K9J5yrukGe2s",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Book Name Predicted_As\n",
            "3                    f4.txt         Fake\n",
            "5   quiet flows the don.txt         Fake\n",
            "1                    f2.txt         Fake\n",
            "10                   o5.txt         Fake\n",
            "15                  o13.txt     Original\n",
            "14                  o12.txt     Original\n",
            "13                   o8.txt     Original\n",
            "12                   o7.txt     Original\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-ee589f4f2043>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Test_Outputs[\"Predicted_As\"]=Books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy = np.array(Training_Accuracy); \n",
        "Test_Accuracy = np.array(Test_Accuracy)\n",
        "  #Ploting Loss per epochs\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot([i for i in range(len(Losses_Per_Epoch))], Losses_Per_Epoch, marker='o',)\n",
        "plt.title('Loss Per Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FKNxte5uLuAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "1529a36f-5a82-4d88-c43b-1d0ea30f8a34"
      },
      "id": "FKNxte5uLuAA",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ploting Training accuracy per epochs\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(Training_Accuracy[:,0], Training_Accuracy[:,1], color='blue', marker='o', label=\"Train Accuracy\")\n",
        "plt.title('Training data accuracy Per Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tzr_teltLyoA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "f6cb3f03-67c6-4261-ba08-f3ca3b89d0ca"
      },
      "id": "Tzr_teltLyoA",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJcCAYAAACxEXM4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xddX3v/9cnNyCQgoYagYSEClWpEMAI3o6OqL/iDUpTEQ4ewQtRW1RsFfFStFpOT/15WqVS21gV1Bi8FaWKWEVGPaJCFORwEY00kKBcNZAQM5fkc/5Ya8LOOHtmTzJr1p5Zr+fjMY+919pr7/2Z/c1m3ny+3712ZCaSJEmaXDPqLkCSJKmJDGGSJEk1MIRJkiTVwBAmSZJUA0OYJElSDQxhkiRJNTCESVNURHwtIs6Y6GN3V0RkRBw6Gc+lqcl/I1LBECZNoojY3PKzPSJ+27J9+ngeKzNfkJmXTPSxkyUilpR/jGfVXUu3i4h1Lf9W7omIiyNinwoee+jnwxPx2JJGZwiTJlFm7jP0A9wJvKRl36qh4wwm3a+GMXpJ+e/mGGAZ8K7x3DkK7f6b3/rvcJ/MPHt3i5U0NkOY1AUioiciNkTE2yLibuATEfGoiPhKRNwXEb8pry9suU9vRLymvH5mRPyfiPhAeex/RcQLdvHYQyLiOxGxKSK+GREXRcSnR6n9rRHxq4j4ZUS8athtL4qI6yPioYhYHxHvabn5O+XlxrL78rSIeFxEfCsiHoiI+yNiVUTsN8pzf6h83Ici4kcR8d9abpsZEe+IiF+Uv8uPImJRedsfRcQ3IuLXZWfpHeX+iyPib4ePS8v2unKMbgQejohZEXFey3PcEhEnD6vxrIi4teX2Y8rX7IvDjrswIj7U7ncdkpl3AV8DnlTe76kRcU1EbIyIn0RET8tj9kbEBRHxPWAL8AdjPf6wms6MiO9FxIcj4sGI+GlEPLfl9gMj4vLydVwbEWe13Nb29S89LyJ+XtZ9UUREeb9DI+Lb5fPdHxGfHU/N0lRiCJO6x2OBRwOLgRUU789PlNsHA78FRpsmOg64DdgfeD/wsaE/bOM89jPAtcB84D3A/2j3hBFxAvAW4PnAYcDzhh3yMPAKYD/gRcDrI+JPytueVV7uV3Zfvg8E8HfAgcATgUVlDe1cBxxF8bp9Bvh8ROxZ3vaXwGnAC4HfA14FbImIecA3gSvL5zkUuGqU5xjutPJ32S8zB4FfAP8N2Bf4G+DTEXEAQES8tKz/FWUNJwIPAJ8GThgKmFF01U4FPjnWk5dB5oXA9RFxEPBV4G/L1+AtwBcj4vdb7vI/KP49zQPuGMfvOeS48nfcH3g38O8R8ejytkuBDRSv458B/zMiji9vG/H1b3ncFwNPAY4ETgH+uNz/PuA/gUcBC4F/2oWapakhM/3xx58afoB1wPPK6z1AP7DnKMcfBfymZbsXeE15/Uxgbcttc4EEHjueYynC3iAwt+X2TwOfblPTx4H/1bL9h+VjHdrm+A8C/1heX1IeO2uU3/lPgOvH8Zr+BlhaXr8NOGmEY05r95jAxcDftmz3ABuGjdmrxqjhhqHnBb4OvKnNcV8Dziqvvxi4ZYx/K5uBjRRB6p+BvYC3AZ8aduzXgTNaxv29Hfw7HHrsoZ+hus4EfglEy/HXUgS7RcA2YF7LbX8HXDza61/elsAzW7Y/B5xXXv8ksBJYWMX7zh9/uunHTpjUPe7LzK1DGxExNyL+NSLuiIiHKKbv9ouImW3uf/fQlcwc6ji0W7zd7tgDgV+37ANYP0rNBw67fadOS0QcFxFXRzGl+iDwOoqOyogiYkFEXBoRd5W/86fHOP4t5VTfgxGxkaIbNXT8IooOznDt9ndqp9cjIl4RETeU02obKaYJx6oB4BLg5eX1lwOfGuN5/yQz98vMxZn555n5W4ou6UuHnrt8/mcCB7Srd4zHHvr5aMttd2VmtmzfQTHuQ/9WNg277aDy+liv890t17fwyL/Vcyk6otdGxM0xbIpbmk4MYVL3yGHbfwU8HjguM3+PR6bv2k0xToRfAY+OiLkt+xa1O7g8vvX2g4fd/hngcmBRZu4L/AuP1D/89wX4n+X+I8rf+eW0+X3L9V/nUkxlPSoz9wMebDl+PfC4Ee66nvZrox6m6AwOeewIx+yoOyIWAx8FzgbmlzXc1EENAF8CjoyIJ1F0wla1OW406yk6Ya0Bau/M/F8j1buLDho2rX0wRXfslxT/VuYNu+2ultra/e5tZebdmXlWZh4IvBb45/B0FpqmDGFS95pHsQ5sY7kG591VP2Fm3gGsAd4TEXMi4mnAS0a5y+eAMyPi8DK4Da9xHkW3ZGtEHAv895bb7gO2s3MgmkcxNfZgud7praM89zyKqdP7gFkRcT7F2qMh/wa8LyIOi8KRETEf+ApwQEScExF7RMS8iDiuvM8NwAsj4tER8VjgnFGeH2BvipBzH0BEvJJywXxLDW+JiCeXNRxaBjfKrucXKNfgZeadYzzXSD4NvCQi/rhcCL9nFB8mWDjmPTv3GOCNETG7XOP2ROCKzFwPXAP8Xfm8RwKvLmuC9q//qCLipS31/4bi9d0+gb+P1DUMYVL3+iDFup/7gR9QLCSfDKcDT6NYQP63wGeBvpEOzMyvUdT5LWBtednqz4H3RsQm4HyK0DZ03y3ABcD3yqm0p1IsbD+GoqP1VeDfR6nz6xSvyc8opsG2svPU2z+Uz/efwEPAx4C9yumz51OEy7uBnwPPKe/zKeAnFOuk/rP83dvKzFuA/w18H7gHOAL4Xsvtny9/x88Amyi6X49ueYhLyvuMNRXZ7vnXAycB76AIguspgut4/9v+H7HzecIua7nthxQfuri//F3+LDMfKG87jWJt3y+By4B3Z+Y3y9tGfP07qOUpwA8jYjNFF/VNmXn7OH8faUqInaf6JWln5SkCfpqZlXfimiYiDgZ+SvEBiofqrme4iDiT4gMdz6y7Fmk6shMmaScR8ZQoztc1ozwFxUkUHRxNoChOnPqXwKXdGMAkVc+zcksa7rEU04DzKc4B9frMvL7ekqaXiNibYvryDuCEmsuRVBOnIyVJkmrgdKQkSVINptx05P77759Lliyp9Dkefvhh9t5770qfQ7vGselOjkv3cmy6k+PSvSZ6bH70ox/dn5m/P9JtUy6ELVmyhDVr1lT6HL29vfT09FT6HNo1jk13cly6l2PTnRyX7jXRYxMRbb+z1elISZKkGhjCJEmSamAIkyRJqsGUWxMmSVITDAwMsGHDBrZu3Vp3KY2y7777cuutt477fnvuuScLFy5k9uzZHd/HECZJUhfasGED8+bNY8mSJURE3eU0xqZNm5g3b9647pOZPPDAA2zYsIFDDjmk4/s5HSlJUhfaunUr8+fPN4BNARHB/Pnzx921NIRJktSlDGBTx66MlSFMkiSpBoYwSZL0Ox544AGOOuoojjrqKB772Mdy0EEH7dju7+8f9b5r1qzhjW9847if84YbbiAiuPLKK3e17CnFECZJ0jSwahUsWQIzZhSXq1bt3uPNnz+fG264gRtuuIHXve51vPnNb96xPWfOHAYHB9ved9myZVx44YXjfs7Vq1fzzGc+k9WrV+9O6WPatm1bpY/fKUOYJElT3KpVsGIF3HEHZBaXK1bsfhAb7swzz+R1r3sdxx13HOeeey7XXnstT3va0zj66KN5+tOfzm233QYUX/3z4he/GID3vOc9vOpVr6Knp4c/+IM/aBvOMpPPf/7zXHzxxXzjG9/YaZH73//933PEEUewdOlSzjvvPADWrl3L8573PJYuXcoxxxzDL37xi52eF+Dss8/m4osvBoqvPXzb297GMcccw+c//3k++tGP8pSnPIWlS5eyfPlytmzZAsC9997LySefzNKlS1m6dCnXXHMN559/Ph/84Ad3PO473/lOPvShD+326+kpKiRJ6nLnnAM33ND+9h/8APr6dt63ZQu8+tXw0Y+OfJ+jjoKWXNGxDRs2cM011zBz5kweeughvvvd7zJr1iy++c1v8o53vIMvfvGLv3Ofn/70p1x99dVs2rSJxz/+8bz+9a//nfNpXXPNNRxyyCE87nGPo6enh69+9assX76cr33ta3z5y1/mhz/8IXPnzuXXv/41AKeffjrnnXceJ598Mlu3bmX79u2sX79+1Nrnz5/Pj3/8Y6CYbj3rrLMAeNe73sXHPvYx3vCGN3Duuefy7Gc/m8suu4xt27axefNmDjzwQP70T/+Uc845h+3bt3PppZdy7bXXjv/FG8YQJknSFDc8gI21f3e89KUvZebMmQA8+OCDnHHGGfz85z8nIhgYGBjxPi960YvYY4892GOPPXjMYx7DPffcw8KFC3c6ZvXq1Zx66qkAnHrqqXzyk59k+fLlfPOb3+SVr3wlc+fOBeDRj340mzZt4q677uLkk08GihOlduJlL3vZjus33XQT73rXu9i4cSObN2/mj//4jwH49re/zWc+8xkAZs6cyb777su+++7L/Pnzuf7667nnnns4+uijmT9/fqcvWVuGMEmSutxYHaslS4opyOEWL4be3omtZe+9995x/a//+q95znOew2WXXca6devo6ekZ8T577LHHjuszZ878nfVk27Zt44tf/CJf/vKXueCCC3ac/HTTpk3jqm3WrFls3759x/bw83a11n7mmWfypS99iaVLl3LxxRfTO8YL9ZrXvIaLL76Yu+++m1e96lXjqqsd14RJkjTFXXABlI2iHebOLfZX6cEHH+Sggw4C2LH2aldcddVVHHnkkaxfv55169Zxxx13sHz5ci677DKe//zn84lPfGLHmq1f//rXzJs3j4ULF/KlL30JgL6+PrZs2cLixYu55ZZb6OvrY+PGjVx11VVtn3PTpk0ccMABDAwMsKpl8dyzn/1sPvKRjwBFOHzwwQcBOPnkk7nyyiu57rrrdnTNdpchTJKkKe7002HlyqLzFVFcrlxZ7K/Sueeey9vf/naOPvroUT8tOZbVq1fvmFocsnz5clavXs0JJ5zAiSeeyLJlyzjqqKP4wAc+AMCnPvUpLrzwQo488kie/vSnc/fdd7No0SJOOeUUnvSkJ3HKKadw9NFHt33O973vfRx33HE84xnP4AlPeMKO/e9///u5+uqrOeKII3jyk5/MLbfcAsCcOXN4znOewymnnLJjOnZ3RWZOyANNlmXLluWaNWsqfY7e3t62LVXVy7HpTo5L93JsulMn43LrrbfyxCc+cXIK0g7tvjty+/btOz5Zedhhh41435HGLCJ+lJnLRjreTpgkSdIobrnlFg499FCe+9zntg1gu8KF+ZIkSaM4/PDDuf322yf8ce2ESZLUpabakqEm25WxqiyERcTHI+LeiLipze0RERdGxNqIuDEijqmqFnWvkb5mY7R9xx//7I6O25V9u1LPZO/r1hpbx6Vba5wKr2MVNVb5nmn6a1vluAA88MCe/PjHD7BmTXLjjfDAA8XPjTfCmjXUvq+osXvq2d0ad8fQKTU6PV/ZkMoW5kfEs4DNwCcz80kj3P5C4A3AC4HjgA9l5nFjPa4L86ePVauKr9UoP3UMwOzZxSd7Wr8bdjL2zZ0LZ5wBl1zSHfVYozV2e41Tte6pVOOXvzzA2962gUMP3cqMLpu3ioC994aHHy6+JqkbjafGCJg/vzh+69at4w5TUJwwduHChQz/JoDRFuZX+unIiFgCfKVNCPtXoDczV5fbtwE9mfmr0R7TEDZ9LFky8skFJUmabIsXw7p1E58BRgthdS7MPwho/ZKnDeW+3wlhEbECWAGwYMGCMc9qu7s2b95c+XMI7rzz2UDUXUaLpLvqGYk1TgxrrM5UqNsaJ8b0qvHOO5Pe3m9PagaYEp+OzMyVwEooOmFVd6nshE2Ogw/urk7YzJnBtm11VzE6a5wY1lidqVC3NU6M6VbjwQcHPT09k5oB6pxlvgtY1LK9sNynhrjgAthrr533zZ4Nc+ZM/r65c4v1acO/9qOueqzRGru9xqlatzVaY7tjq/6KpxFlZmU/wBLgpja3vQj4GkWf8KnAtZ085pOf/OSs2tVXX135c6jwgQ9kFksmMxcvzvz0p4ufxYszI0bat73D48a/L3PiH7M5NW6fAjVOhdexihqre8/42lY3Lt1R41R4HSeuxiETnQGANdkm01T56cjVQA+wP3AP8G5gdhn8/iUiAvgwcAKwBXhlZo654t6F+dPLrbfC4YfDpZfCy1429vGOTXdyXLqXY9OdHJfuNS0W5mfmaWPcnsBfVPX8mhoGBorLYZ/olSRp2uuyM4+oaQYHi8tZU+IjIpIkTRxDmGo1FMLshEmSmsYQploNTUfaCZMkNY0hTLVyOlKS1FSGMNXKhfmSpKYyhKlWdsIkSU1lCFOt7IRJkprKEKZa2QmTJDWVIUy1MoRJkprKEKZaOR0pSWoqQ5hqZSdMktRUhjDVyk6YJKmpDGGqlZ0wSVJTGcJUK787UpLUVIYw1crvjpQkNZUhTLVyOlKS1FSGMNXKhfmSpKYyhKlWdsIkSU1lCFOtBgYgAmbOrLsSSZImlyFMtRoctAsmSWomQ5hqNTjoejBJUjMZwlSrgQE7YZKkZjKEqVZOR0qSmsoQploNDDgdKUlqJkOYamUnTJLUVIYw1cpOmCSpqQxhqpWdMElSUxnCVCtPUSFJaipDmGrlKSokSU1lCFOtnI6UJDWVIUy1cmG+JKmpDGGqlZ0wSVJTGcJUKzthkqSmMoSpVnbCJElNZQhTrQxhkqSmMoSpVk5HSpKayhCmWtkJkyQ1lSFMtbITJklqKkOYamUnTJLUVIYw1cpOmCSpqQxhqpWdMElSUxnCVCtDmCSpqQxhqpXTkZKkpjKEqVZ2wiRJTWUIU63shEmSmsoQplrZCZMkNZUhTLWyEyZJaipDmGqzfTtk2gmTJDWTIUy1GRwsLg1hkqQmMoSpNgMDxaXTkZKkJjKEqTZ2wiRJTWYIU23shEmSmswQptrYCZMkNZkhTLUZ6oQZwiRJTWQIU22GOmFOR0qSmsgQpto4HSlJajJDmGrjwnxJUpMZwlQbO2GSpCYzhKk2dsIkSU1mCFNt7IRJkprMEKbaGMIkSU1mCFNtnI6UJDWZIUy1sRMmSWoyQ5hqYydMktRkhjDVxk6YJKnJDGGqjZ0wSVKTGcJUGzthkqQmM4SpNoYwSVKTGcJUG6cjJUlNZghTbeyESZKarNIQFhEnRMRtEbE2Is4b4fbFEXFVRNwYEb0RsbDKetRd7IRJkpqsshAWETOBi4AXAIcDp0XE4cMO+wDwycw8Engv8HdV1aPuYydMktRkVXbCjgXWZubtmdkPXAqcNOyYw4FvldevHuF2TWN2wiRJTVZlD+IgYH3L9gbguGHH/AT4U+BDwMnAvIiYn5kPtB4UESuAFQALFiygt7e3qpoB2Lx5c+XPIbjttkXA47jmmu+w117bO7qPY9OdHJfu5dh0J8ele03m2NQ9EfQW4MMRcSbwHeAuYNvwgzJzJbASYNmyZdnT01NpUb29vVT9HILvf7+4PP74Z7HHHp3dx7HpTo5L93JsupPj0r0mc2yqDGF3AYtatheW+3bIzF9SdMKIiH2A5Zm5scKa1EWcjpQkNVmVa8KuAw6LiEMiYg5wKnB56wERsX9EDNXwduDjFdajLjM4CBEwwxOlSJIaqLI/f5k5CJwNfB24FfhcZt4cEe+NiBPLw3qA2yLiZ8AC4IKq6lH3GRiwCyZJaq5K14Rl5hXAFcP2nd9y/QvAF6qsQd1rcNDTU0iSmsuJINVmYMAQJklqLkOYajM46HSkJKm5DGGqjdORkqQmM4SpNi7MlyQ1mSFMtbETJklqMkOYamMnTJLUZIYw1cZOmCSpyQxhqo2nqJAkNZkhTLXxFBWSpCYzhKk2TkdKkprMEKbauDBfktRkhjDVxk6YJKnJDGGqjZ0wSVKTGcJUGzthkqQmM4SpNp6iQpLUZIYw1cZTVEiSmswQpto4HSlJajJDmGrjwnxJUpMZwlQbO2GSpCYzhKk2dsIkSU1mCFNt7IRJkprMEKbaeIoKSVKTGcJUG09RIUlqMkOYauN0pCSpyQxhqo0L8yVJTWYIU23shEmSmswQplps2waZhjBJUnMZwlSLwcHi0ulISVJTGcJUi6EQZidMktRUhjDVYmCguLQTJklqKkOYamEnTJLUdIYw1cJOmCSp6QxhqoWdMElS0xnCVIuhTpghTJLUVIYw1cJTVEiSms4Qplo4HSlJajpDmGrhwnxJUtMZwlQLO2GSpKYzhKkWdsIkSU1nCFMt7IRJkprOEKZaeIoKSVLTGcJUC09RIUlqOkOYauF0pCSp6QxhqoUL8yVJTWcIUy3shEmSms4Qplq4MF+S1HSGMNXChfmSpKYzhKkWdsIkSU1nCFMt7IRJkprOEKZauDBfktR0hjDVwlNUSJKazhCmWtgJkyQ1nSFMtXBhviSp6QxhqoUL8yVJTWcIUy3shEmSms4QploMDsKMGcWPJElN5J9A1WJw0C6YJKnZDGGqxcCA68EkSc1mCFMt7IRJkprOEKZaDAwYwiRJzWYIUy0GB52OlCQ1myFMtbATJklqOkOYamEnTJLUdIYw1cKF+ZKkpjOEqRaeokKS1HSGMNXCTpgkqekMYaqFC/MlSU1nCFMtXJgvSWo6Q5hqYSdMktR0hjDVwk6YJKnpKg1hEXFCRNwWEWsj4rwRbj84Iq6OiOsj4saIeGGV9ah7uDBfktR0lYWwiJgJXAS8ADgcOC0iDh922LuAz2Xm0cCpwD9XVY+6i9ORkqSmq7ITdiywNjNvz8x+4FLgpGHHJPB75fV9gV9WWI+6iNORkqSmq7IXcRCwvmV7A3DcsGPeA/xnRLwB2Bt43kgPFBErgBUACxYsoLe3d6Jr3cnmzZsrf46m27hxGfvs81t6e28e1/0cm+7kuHQvx6Y7OS7dazLHpu4JodOAizPzf0fE04BPRcSTMnN760GZuRJYCbBs2bLs6emptKje3l6qfo6m22MPOOCAfcb9Ojs23clx6V6OTXdyXLrXZI5NldORdwGLWrYXlvtavRr4HEBmfh/YE9i/wprUJVwTJklquipD2HXAYRFxSETMoVh4f/mwY+4EngsQEU+kCGH3VViTuoRrwiRJTVdZCMvMQeBs4OvArRSfgrw5It4bESeWh/0VcFZE/ARYDZyZmVlVTeoenqJCktR0lf4ZzMwrgCuG7Tu/5fotwDOqrEHdyelISVLTecZ81cLpSElS0xnCVAs7YZKkpjOEqRZ2wiRJTWcIUy1cmC9JajpDmCZdZjEdaSdMktRkhjBNuu3l9yHYCZMkNZkhTJNuYKC4NIRJkprMEKZJNzhYXDodKUlqMkOYJp2dMEmSDGGqgZ0wSZIMYarBUAizEyZJajJDmCad05GSJBnCVAOnIyVJMoSpBnbCJEkyhKkGdsIkSTKEqQZ2wiRJMoSpBnbCJEkyhKkGnqJCkiRDmGrgdKQkSYYw1cDpSEmSDGGqgZ0wSZIMYaqBnTBJkgxhqoGdMEmSDGGqgZ0wSZIMYaqBp6iQJMkQpho4HSlJkiFMNXA6UpIkQ5hqYCdMkiRDmGpgJ0ySJEOYamAnTJIkQ5hqYCdMkiRDmGrgKSokSTKEqQZOR0qSZAhTDeyESZJkCFMNBgZgxoziR5KkpvLPoCbd4KCL8iVJMoRp0g0MOBUpSZIhTJNucNAQJkmSIUyTzulISZIMYaqB05GSJBnCVAM7YZIkGcJUAzthkiQZwlQDO2GSJBnCVAM7YZIkGcJUA09RIUmSIUw1cDpSkiRDmGrgdKQkSYYw1cBOmCRJhjDVwE6YJEmGMNXATpgkSYYw1cBPR0qSZAhTDZyOlCTJEKYaOB0pSZIhTDWwEyZJkiFMNbATJkmSIUw1sBMmSZIhTDWwEyZJkiFMNfAUFZIkGcJUA6cjJUkyhKkGTkdKkmQIUw3shEmSZAhTDeyESZJkCNMky3RhviRJ0EEIi4iXRIRhTRNi27bi0hAmSWq6TsLVy4CfR8T7I+IJVRek6W1wsLh0OlKS1HRjhrDMfDlwNPAL4OKI+H5ErIiIeZVXp2lnYKC4tBMmSWq6jqYZM/Mh4AvApcABwMnAjyPiDRXWpmnITpgkSYVO1oSdGBGXAb3AbODYzHwBsBT4q2rL03RjJ0ySpEInfwqXA/+Ymd9p3ZmZWyLi1dWUpenKTpgkSYVOQth7gF8NbUTEXsCCzFyXmVdVVZimJzthkiQVOlkT9nlge8v2tnLfmCLihIi4LSLWRsR5I9z+jxFxQ/nzs4jY2FnZmqqGOmGGMElS03Xyp3BWZvYPbWRmf0TMGetOETETuAh4PrABuC4iLs/MW1oe680tx7+B4lOYmsacjpQkqdBJJ+y+iDhxaCMiTgLu7+B+xwJrM/P2MsRdCpw0yvGnAas7eFxNYU5HSpJU6ORP4euAVRHxYSCA9cArOrjfQeWxQzYAx410YEQsBg4BvtXm9hXACoAFCxbQ29vbwdPvus2bN1f+HE21du0+wDJuu+0mens7yfI7c2y6k+PSvRyb7uS4dK/JHJsxQ1hm/gJ4akTsU25vrqCOU4EvZOa2NjWsBFYCLFu2LHt6eioo4RG9vb1U/RxNtffexeVRRz2JXXmJHZvu5Lh0L8emOzku3Wsyx6ajSaGIeBHwR8CeEQFAZr53jLvdBSxq2V5Y7hvJqcBfdFKLpjbXhEmSVOjkZK3/QvH9kW+gmI58KbC4g8e+DjgsIg4pF/KfClw+wuM/AXgU8P1x1K0pyjVhkiQVOlmY//TMfAXwm8z8G+BpwB+OdafMHATOBr4O3Ap8LjNvjoj3ti70pwhnl2Zmjr98TTWeokKSpEInfwq3lpdbIuJA4AGK748cU2ZeAVwxbN/5w7bf08ljaXpwOlKSpEInIew/ImI/4P8Hfgwk8NFKq9K05XSkJEmFUf8URsQM4KrM3Ah8MSK+AuyZmQ9OSnWaduyESZJUGHVNWGZupzjr/dB2nwFMu8NOmCRJhU4W5l8VEctj6NwU0m5wYb4kSYVOQthrKb6wuy8iHoqITRHxUMV1aZoa6oQ5HSlJarpOzpg/bzIKUTPYCZMkqTDmn8KIeNZI+zPzO8WOZq8AABbVSURBVBNfjqY7F+ZLklTopB/x1pbrewLHAj8Cjq+kIk1rLsyXJKnQyXTkS1q3I2IR8MHKKtK0ZidMkqRCJwvzh9sAPHGiC1Ez2AmTJKnQyZqwf6I4Sz4Uoe0oijPnS+PmwnxJkgqd/Clc03J9EFidmd+rqB5Nc56iQpKkQich7AvA1szcBhARMyNibmZuqbY0TUd2wiRJKnR0xnxgr5btvYBvVlOOprvBQZg5E/z+BUlS03USwvbMzM1DG+X1udWVpOlsYMAumCRJ0FkIezgijhnaiIgnA7+triRNZ4ODrgeTJAk6WxN2DvD5iPglEMBjgZdVWpWmLTthkiQVOjlZ63UR8QTg8eWu2zJzoNqyNF0NDhrCJEmCDqYjI+IvgL0z86bMvAnYJyL+vPrSNB05HSlJUqGTNWFnZebGoY3M/A1wVnUlaTpzOlKSpEInIWxmxCMnFIiImcCc6krSdGYnTJKkQic9iSuBz0bEv5bbrwW+Vl1Jms7shEmSVOjkz+HbgBXA68rtGyk+ISmNm50wSZIKY05HZuZ24IfAOuBY4Hjg1mrL0nRlJ0ySpELbP4cR8YfAaeXP/cBnATLzOZNTmqYjT1EhSVJhtD+HPwW+C7w4M9cCRMSbJ6UqTVtOR0qSVBhtOvJPgV8BV0fERyPiuRRnzJd2mdORkiQV2oawzPxSZp4KPAG4muLrix4TER+JiP9vsgrU9GInTJKkQicL8x/OzM9k5kuAhcD1FJ+YlMbNTpgkSYVOTta6Q2b+JjNXZuZzqypI05sL8yVJKowrhEm7a2DA6UhJksAQpklmJ0ySpIIhTJPKhfmSJBUMYZpULsyXJKlgCNOkshMmSVLBEKZJZSdMkqSCIUyTyoX5kiQVDGGaVJ6iQpKkgiFMk8pOmCRJBUOYJpUL8yVJKhjCNKlcmC9JUsEQpkmTCdu22QmTJAkMYZpEg4PFpZ0wSZIMYZpEhjBJkh5hCNOkGRgoLp2OlCTJEKZJZCdMkqRHGMI0aYZCmJ0wSZIMYZpEQ9ORdsIkSTKEaRI5HSlJ0iMMYZo0LsyXJOkRhrAOrFoFS5bAjBnF5apV3bVvqtR42WXF5StesfN+SZKaKDKz7hrGZdmyZblmzZpKn6O3t5eenh6gCAorVsCWLY/cPns2REB/f/375s6FM86ASy7p/ho/8QnYunXn/StXwumn07HWsVH3cFy6l2PTnRyX7jXRYxMRP8rMZSPd5uqcMbzznTuHG3hkWq0b9m3ZAv/6r7B9e3fUM54at2wpXt/xhDBJkqYLpyPHcOeddVcwtuHhphu1q3EqvL6SJFXBEDaGgw+uu4KxzZgCo9iuxqnw+kqSVIUp8Oe7XhdcAHvssfO+2bNhzpzu2Dd3Lrz2tcVlN9Qznhrnzi1eX0mSmsgQNobTT4dzzimuR8DixcUC849/vLhe976VK+Gf/7m47IZ6xlPjeBflS5I0nfjpyBEM/2TEV74CL3kJXHstPOUplT61xuAnirqT49K9HJvu5Lh0r8n8dKSdsA709RWXw6clJUmSdpUhrAND57wyhEmSpIliCOvAUCds+IJzSZKkXWUI64DTkZIkaaIZwjowNB1pJ0ySJE0UQ1gH7IRJkqSJZgjrgCFMkiRNNENYB4amI2fPrrcOSZI0fRjCOtDXV6wHi6i7EkmSNF0YwjrQ3+9UpCRJmliGsA4MdcIkSZImiiGsA319dsIkSdLEqjSERcQJEXFbRKyNiPPaHHNKRNwSETdHxGeqrGdXOR0pSZIm2qyqHjgiZgIXAc8HNgDXRcTlmXlLyzGHAW8HnpGZv4mIx1RVz+5wOlKSJE20KjthxwJrM/P2zOwHLgVOGnbMWcBFmfkbgMy8t8J6dpnTkZIkaaJV1gkDDgLWt2xvAI4bdswfAkTE94CZwHsy88rhDxQRK4AVAAsWLKC3t7eKenfYvHnzTs9x991H0Nc3m97eH1f6vBrb8LFRd3Bcupdj050cl+41mWNTZQjr9PkPA3qAhcB3IuKIzNzYelBmrgRWAixbtix7enoqLaq3t5fW59h7b5g1C6p+Xo1t+NioOzgu3cux6U6OS/eazLGpcjryLmBRy/bCcl+rDcDlmTmQmf8F/IwilHUVpyMlSdJEqzKEXQccFhGHRMQc4FTg8mHHfImiC0ZE7E8xPXl7hTXtkv5+F+ZLkqSJVVkIy8xB4Gzg68CtwOcy8+aIeG9EnFge9nXggYi4BbgaeGtmPlBVTbvKTpgkSZpola4Jy8wrgCuG7Tu/5XoCf1n+dC3PEyZJkiaaZ8zvgOcJkyRJE80Q1gGnIyVJ0kQzhHXA6UhJkjTRDGEdcDpSkiRNNENYB5yOlCRJE80QNoZMzxMmSZImniFsDAMDxaWdMEmSNJEMYWPo6ysuDWGSJGkiGcLG0N9fXDodKUmSJpIhbAx2wiRJUhUMYWMY6oQZwiRJ0kQyhI1hqBPmdKQkSZpIhrAxOB0pSZKqYAgbg9ORkiSpCoawMTgdKUmSqmAIG4PTkZIkqQqGsDF4njBJklQFQ9gY7IRJkqQqGMLGYAiTJElVMISNwelISZJUBUPYGOyESZKkKhjCxuB5wiRJUhUMYWPwPGGSJKkKhrAxOB0pSZKqYAgbg9ORkiSpCoawMfT1wYwZMHNm3ZVIkqTpxBA2hr4+u2CSJGniGcLG0N/vonxJkjTxDGFjsBMmSZKqYAgbgyFMkiRVwRA2BqcjJUlSFQxhY7ATJkmSqmAIG0N/vyFMkiRNPEPYGPr6nI6UJEkTzxA2BqcjJUlSFQxhY3A6UpIkVcEQNganIyVJUhUMYWNwOlKSJFXBEDYGzxMmSZKqYAgbg50wSZJUBUPYGAxhkiSpCoawMTgdKUmSqmAIG4OdMEmSVAVD2Bg8T5gkSaqCIWwU27fD4KDTkZIkaeIZwkbR11dc2gmTJEkTzRA2iv7+4tIQJkmSJpohbBRDnTCnIyVJ0kQzhI3C6UhJklQVQ9gohqYj7YRJkqSJZggbhZ0wSZJUFUPYKAxhkiSpKoawUTgdKUmSqmIIG4WdMEmSVBVD2Cg8T5gkSaqKIWwUnidMkiRVxRA2CqcjJUlSVQxho3A6UpIkVcUQNgqnIyVJUlUMYaNwOlKSJFXFEDYKzxMmSZKqYggbhZ0wSZJUFUPYKAxhkiSpKoawUQxNR86eXW8dkiRp+jGEjaKvrwhgM3yVJEnSBDNejKK/36lISZJUDUPYKPr6/GSkJEmqhiFsFH19dsIkSVI1DGGjcDpSkiRVxRA2CqcjJUlSVSoNYRFxQkTcFhFrI+K8EW4/MyLui4gbyp/XVFnPeDkdKUmSqjKrqgeOiJnARcDzgQ3AdRFxeWbeMuzQz2bm2VXVsTv6++2ESZKkalTZCTsWWJuZt2dmP3ApcFKFzzfh7IRJkqSqVNYJAw4C1rdsbwCOG+G45RHxLOBnwJszc/3wAyJiBbACYMGCBfT29k58tS02b95Mb28v9957FLNmJb29P6n0+dS5obFRd3Fcupdj050cl+41mWNTZQjrxH8AqzOzLyJeC1wCHD/8oMxcCawEWLZsWfb09FRaVG9vLz09Pey1FzzqUVD186lzQ2Oj7uK4dC/Hpjs5Lt1rMsemyunIu4BFLdsLy307ZOYDmVl+TTb/Bjy5wnrGzelISZJUlSpD2HXAYRFxSETMAU4FLm89ICIOaNk8Ebi1wnrGzRAmSZKqUtl0ZGYORsTZwNeBmcDHM/PmiHgvsCYzLwfeGBEnAoPAr4Ezq6pnV/jpSEmSVJVK14Rl5hXAFcP2nd9y/e3A26usYXfYCZMkSVXxjPmj8GuLJElSVQxho/BriyRJUlUMYaNwOlKSJFXFENZGptORkiSpOoawNgYHiyDmdKQkSaqCIayNvvIUsnbCJElSFQxhbfT3F5d2wiRJUhUMYW3YCZMkSVUyhLVhCJMkSVUyhLXhdKQkSaqSIawNO2GSJKlKhrA2hjphhjBJklQFQ1gbQ50wpyMlSVIVDGFtOB0pSZKqZAhrw+lISZJUJUNYG05HSpKkKhnC2nA6UpIkVckQ1obnCZMkSVUyhLVhJ0ySJFXJENaGIUySJFXJENaG05GSJKlKhrA27IRJkqQqGcLa8DxhkiSpSoawNvr6IAJmzqy7EkmSNB0Zwtro6yu6YBF1VyJJkqYjQ1gb/f1ORUqSpOoYwtro6/OTkZIkqTqGsDaGpiMlSZKqYAhro7/fTpgkSaqOIawNO2GSJKlKhrA2DGGSJKlKhrA2nI6UJElVMoS1YSdMkiRVyRDWhucJkyRJVTKEteF5wiRJUpUMYW04HSlJkqpkCGvD6UhJklQlQ1gbTkdKkqQqGcLacDpSkiRVyRDWhucJkyRJVTKEtWEnTJIkVckQ1oYhTJIkVckQNoLt22Fw0OlISZJUHUPYCAYHi5fFTpgkSaqKIWwEAwMBGMIkSVJ1DGEjGBgoXhanIyVJUlUMYSMYCmF2wiRJUlUMYSNwOlKSJFXNEDYCpyMlSVLVDGEjcDpSkiRVzRA2gqHpSDthkiSpKoawEdgJkyRJVTOEjcAQJkmSqmYIG4HTkZIkqWqGsBHYCZMkSVUzhI3A84RJkqSqGcJG4HnCJElS1QxhI3A6UpIkVc0QNgKnIyVJUtUMYSNwOlKSJFXNEDYCpyMlSVLVDGEjGBz0PGGSJKlahrAR9PfPYNYsmOGrI0mSKmLMGMHAwAynIiVJUqUMYSMYHAynIiVJUqUMYSPo77cTJkmSqmUIG8HgoCFMkiRVyxA2goEBpyMlSVK1DGEjcGG+JEmqmiFsBIYwSZJUtUpDWEScEBG3RcTaiDhvlOOWR0RGxLIq6+mU05GSJKlqlYWwiJgJXAS8ADgcOC0iDh/huHnAm4AfVlXLeNkJkyRJVauyE3YssDYzb8/MfuBS4KQRjnsf8PfA1gprGZeBgRl2wiRJUqVmVfjYBwHrW7Y3AMe1HhARxwCLMvOrEfHWdg8UESuAFQALFiygt7d34qtt0dd3NJs3309v702VPo/Gb/PmzZWPv8bPcelejk13cly612SOTZUhbFQRMQP4B+DMsY7NzJXASoBly5ZlT09PpbVt2/YwBx64L1U/j8avt7fXcelCjkv3cmy6k+PSvSZzbKqcjrwLWNSyvbDcN2Qe8CSgNyLWAU8FLu+GxflOR0qSpKpVGcKuAw6LiEMiYg5wKnD50I2Z+WBm7p+ZSzJzCfAD4MTMXFNhTR0ZGAgX5kuSpEpVFsIycxA4G/g6cCvwucy8OSLeGxEnVvW8E8GvLZIkSVWrdE1YZl4BXDFs3/ltju2pspbx6O93OlKSJFXLM+aPwOlISZJUNUPYCJyOlCRJVTOEDTM4CNu3+7VFkiSpWoawYfr6iks7YZIkqUqGsGH6+4tLO2GSJKlKhrBh7IRJkqTJYAgbxhAmSZImgyFsGKcjJUnSZDCEDWMnTJIkTQZD2DCGMEmSNBkMYcM4HSlJkiaDIazFqlVw8snF9TPOKLYlSZKqUOkXeE8lq1bBihWwZUuxfe+9xTbA6afXV5ckSZqe7ISV3vnORwLYkC1biv2SJEkTzRBWuvPO8e2XJEnaHYaw0sEHj2+/JEnS7jCElS64AObO3Xnf3LnFfkmSpIlmCCudfjqsXAmLF0NEsnhxse2ifEmSVAVDWIvTT4d16+Bb3/o269YZwCRJUnUMYZIkSTUwhEmSJNXAECZJklQDQ5gkSVINDGGSJEk1MIRJkiTVwBAmSZJUA0OYJElSDQxhkiRJNTCESZIk1cAQJkmSVANDmCRJUg0MYZIkSTUwhEmSJNXAECZJklQDQ5gkSVINDGGSJEk1MIRJkiTVwBAmSZJUA0OYJElSDSIz665hXCLiPuCOip9mf+D+ip9Du8ax6U6OS/dybLqT49K9JnpsFmfm7490w5QLYZMhItZk5rK669Dvcmy6k+PSvRyb7uS4dK/JHBunIyVJkmpgCJMkSaqBIWxkK+suQG05Nt3Jcelejk13cly616SNjWvCJEmSamAnTJIkqQaGMEmSpBoYwoaJiBMi4raIWBsR59VdT1NFxKKIuDoibomImyPiTeX+R0fENyLi5+Xlo+qutakiYmZEXB8RXym3D4mIH5bvnc9GxJy6a2yaiNgvIr4QET+NiFsj4mm+Z7pDRLy5/G/ZTRGxOiL29D1Tj4j4eETcGxE3tewb8X0ShQvLMboxIo6ZyFoMYS0iYiZwEfAC4HDgtIg4vN6qGmsQ+KvMPBx4KvAX5VicB1yVmYcBV5XbqsebgFtbtv8e+MfMPBT4DfDqWqpqtg8BV2bmE4ClFOPje6ZmEXEQ8EZgWWY+CZgJnIrvmbpcDJwwbF+798kLgMPKnxXARyayEEPYzo4F1mbm7ZnZD1wKnFRzTY2Umb/KzB+X1zdR/DE5iGI8LikPuwT4k3oqbLaIWAi8CPi3cjuA44EvlIc4NpMsIvYFngV8DCAz+zNzI75nusUsYK+ImAXMBX6F75laZOZ3gF8P293ufXIS8Mks/ADYLyIOmKhaDGE7OwhY37K9odynGkXEEuBo4IfAgsz8VXnT3cCCmspqug8C5wLby+35wMbMHCy3fe9MvkOA+4BPlNPE/xYRe+N7pnaZeRfwAeBOivD1IPAjfM90k3bvk0pzgSFMXS0i9gG+CJyTmQ+13pbF+VU8x8oki4gXA/dm5o/qrkU7mQUcA3wkM48GHmbY1KPvmXqU64tOogjKBwJ787vTYeoSk/k+MYTt7C5gUcv2wnKfahARsykC2KrM/Pdy9z1DreDy8t666muwZwAnRsQ6iin74ynWIu1XTrWA7506bAA2ZOYPy+0vUIQy3zP1ex7wX5l5X2YOAP9O8T7yPdM92r1PKs0FhrCdXQccVn5iZQ7FwsnLa66pkco1Rh8Dbs3Mf2i56XLgjPL6GcCXJ7u2psvMt2fmwsxcQvEe+VZmng5cDfxZeZhjM8ky825gfUQ8vtz1XOAWfM90gzuBp0bE3PK/bUNj43ume7R7n1wOvKL8lORTgQdbpi13m2fMHyYiXkix3mUm8PHMvKDmkhopIp4JfBf4vzyy7ugdFOvCPgccDNwBnJKZwxdYapJERA/wlsx8cUT8AUVn7NHA9cDLM7OvzvqaJiKOoviwxBzgduCVFP+z7XumZhHxN8DLKD75fT3wGoq1Rb5nJllErAZ6gP2Be4B3A19ihPdJGZo/TDF9vAV4ZWaumbBaDGGSJEmTz+lISZKkGhjCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRNKxGxLSJuaPmZsC+sjoglEXHTRD2epGabNfYhkjSl/DYzj6q7CEkai50wSY0QEesi4v0R8X8j4tqIOLTcvyQivhURN0bEVRFxcLl/QURcFhE/KX+eXj7UzIj4aETcHBH/GRF71fZLSZrSDGGSppu9hk1Hvqzltgcz8wiKM2B/sNz3T8AlmXkksAq4sNx/IfDtzFxK8R2MN5f7DwMuysw/AjYCyyv+fSRNU54xX9K0EhGbM3OfEfavA47PzNvLL4e/OzPnR8T9wAGZOVDu/1Vm7h8R9wELW79GJiKWAN/IzMPK7bcBszPzb6v/zSRNN3bCJDVJtrk+Hq3f7bcN19ZK2kWGMElN8rKWy++X168BTi2vn07xxfEAVwGvB4iImRGx72QVKakZ/D84SdPNXhFxQ8v2lZk5dJqKR0XEjRTdrNPKfW8APhERbwXuA15Z7n8TsDIiXk3R8Xo98KvKq5fUGK4Jk9QI5ZqwZZl5f921SBI4HSlJklQLO2GSJEk1sBMmSZJUA0OYJElSDQxhkiRJNTCESZIk1cAQJkmSVIP/By6z4ncNcSbRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ploting Test accuracy per epochs\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(Test_Accuracy[:,0], Test_Accuracy[:,1], color='red', marker='o',label=\"Test Accuracy\")\n",
        "plt.title('Test data accuracy Per Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "_r6Noy43L4yp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "47c586ba-ac12-4637-eeaa-3be0be6d0727"
      },
      "id": "_r6Noy43L4yp",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAJcCAYAAAC8DwN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcdZnv+++TTjfYIYZLMIMEknBEAYUEyEYEt0QQRbdc1FGDURxeOtm4R5zxdkSYcZA9nJe6naODFzSOAYFIQFRAwbu0cOQiiSBykTFggARQEhIgxNCV7uf8sVY11d1Vnequy+9Z1Z/361Wv7lpVtdava9WT+ub3rFpl7i4AAADEMCX1AAAAAPA8whkAAEAghDMAAIBACGcAAACBEM4AAAACIZwBAAAEQjgDMCFmttbMXpd6HIiL1wgwMYQzoIDMbEvFZdDM/lpxfckE1tdnZu9vxVjz9buZvaRV6+8U+X7Ylu/HDWb2PTPbqwXrLl9+0Ix1A2guwhlQQO6+S/ki6WFJJ1YsW5F6fJ3EMu38t/KD+X59qaRdJX1hvCsws66x1l1xObGRgQJoDcIZ0EHMbIqZnWVmD5jZRjO70sx2z2/b2cwuy5dvNrPbzWyWmZ0v6b9L+nI+m/LlGut+j5k9lD/+nBG3HWFmt+TrfczMvmxmPfltN+Z3+12+/nea2W5m9kMze8LMNuW/zx7j7yr/Tc+Y2b1m9pYRt/+9md1Xcfth+fJ98tmnJ/Jxfzlffq6ZXVbx+Ln57N7U/HqfmZ1vZr+WtFXSfmZ2esU2HjSz/zliDCeb2Z1m9nQ+1hPM7O1mtnrE/T5iZtfU3Ik5d39S0nclvSJ/3AFm9jMze9LM7jezd1Ss82Izu9DMrjezZyW9dkfrHzGmRWa2zszOzmfs1lbOwJrZDDO7JH8eHzKzf64MrLWe/9wCM7vLzJ4ysyvMbOf8MTPz/b45/5tuanMIBsKiEIDOcqakUyQdI+nFkjZJ+kp+23slzZC0j6Q9JJ0h6a/ufo6km/T8rMoHR67UzA6SdKGk9+Tr3UNSZZgakPRhSTMlvUrScZL+lyS5+2vy+8zP13+Fsn97LpI0R9K+kv4qqWoozD2gLEDOkPRpSZeV231m9nZJ50o6TdILJZ0kaWM+e/RDSQ9Jmitpb0krx9jGSO+RtFTS9Hwdf5H05nwbp0v6QkUIPELSJZI+rmy26zWS1kq6VtI8MztwxHov2dHGzWympLdJusPMpkn6maRvS3qRpMWSvprvl7J3STo/H+//N46/s+xvlO2/vZW9VpaZ2cvy276k7LnfT9lr6zRlz0HN579ive+QdIKkeZIOkfR3+fKPSlonaU9JsySdLYnvEwREOAM6zRmSznH3de7+nLI3zb/NZ4RKykLVS9x9wN1Xu/vTda73byX90N1vzNf7L5IGyzfm67rV3be7+1pJX1f2Jl6Vu2909++6+1Z3f0ZZqBjr/t9x90fdfTAPd3+UdER+8/slfc7db/fMGnd/KL/9xZI+7u7Puvs2dx9PaLnY3e/J/6aSu1/n7g/k2/iVpJ8qC4yS9D5Jy939Z/kY17v7H/Ln6gpJ75YkM3u5sqD4wzG2e4GZbZb0O0mPSfqIslC41t0vysdzh7JZtbdXPO4ad/91vv1tY6274vK/R9z+L+7+XP73XSfpHXnIXSzpk+7+TL5//11ZyJRqP/9D28z33ZOSfiBpQb68JGkvSXPy5/cm58ueAUmEM6DTzJH0/fKbr6T7lM1qzZJ0qaSfSFppZo+a2efMrLvO9b5Y0iPlK+7+rCpmR8zspXmL6nEze1rS/6NsFqYqM+s1s6/nLbKnJd0oaVercayUmZ2WtwzLf9crKta/j7KZtZH2kfSQu2+v828c6ZHKK2b2RjO7NW/BbZb0pjrGIEnfkvQuMzNlgebKPLTV8iF339Xd93b3Je7+hLL9+srKYCVpibLZrqrj3cG6y5d/qbhtU75fyx5Stt9nSurOr1fetnf++1h/uyQ9XvH7Vkm75L//H0lrJP00bxOfVcf4gUmBcAZ0lkckvXHEG/DO+UxOyd0/7e4HSTpK2WzMafnjdjRj8ZiyN2FJWbhSNgtXdqGkP0ja391fqKxFZWOs76OSXibplfn9y63PUY8xszmSviHpg5L2cPddJd1dcd9HJP1fVbbxiKR9y8eRjfCspN6K639T5T5Dz4mZ7aRspurzkmblY7i+jjHI3W+V1K9slu1dykLyeD0i6Vcj9usu7v6BauOdoN3y9mnZvpIelbRB2SzXnBG3ra8YW9W/fSz5LNxH3X0/Za3Qj5jZcRMaOdBhCGdAZ/mapPPzQCMz29PMTs5/f62ZHZzPTj2t7A233Jr8s7LjiWq5StKbzezVlh3of56G//sxPV/nFjM7QNIHRjx+5PqnKzvObLNlH1j41zG2PU1Z8Hgi/ztOV36QfO4/JX3MzA63zEvyv/83ykLlZ8xsmmUfiDg6f8ydkl5jZvua2QxJnxxj+5LUI2mnfAzbzeyNkl5fcfs3JZ1uZsdZ9qGMvfPnoewSZcfUlcbZWi37oaSXWvahjO788t9GHMvWDJ82sx4z++/Kwvt33H1A0pXKXlfT8+f2I5LKH6io9fyPyczenN/XJD2lbIZ3cAcPAyYFwhnQWf5D2UHoPzWzZyTdKumV+W1/oyxkPa2s3fkrPT+L8x/Kjk3bZGYXjFypu98j6R+UHZD+mLIPGqyruMvHlM0KPaNsluuKEas4V9K38pbcOyR9UdILlM3K3Crpx7X+IHe/V9kxTrcoC3kHS/p1xe3fUXbM2rfz7V8tafc8VJwo6SXKTjeyTtI788f8LB/jXZJWa+xjwJQfF/chZSFlU/63Xltx+2+Uf0hAWdD4lYbPNF2qLFBepgnIt/96Zcd+PaqsVfhZZYFxPMqfyC1fKj9J+riyv+1RSSskneHuf8hvO1PZbOODyj5s8G1Jy/OxVX3+6xjL/pJ+LmmLsn37VXe/YZx/D9CRjOMvAaC1zOwFyj7teZi7/zH1eEYys0WSLnP3mqczAdA+zJwBQOt9QNLtEYMZgHiqHSgLAGgSM1ur7IMDpyQeCoCCoK0JAAAQCG1NAACAQDqmrTlz5kyfO3duy7fz7LPPatq0aTu+I9qK/RIX+yYm9ktc7JuYmr1fVq9evcHd96x2W8eEs7lz52rVqlUt305fX58WLVrU8u1gfNgvcbFvYmK/xMW+ianZ+8XMHqp1G21NAACAQAhnAAAAgRDOAAAAAumYY84AAJisSqWS1q1bp23btqUeSseaMWOG7rvvvnE/buedd9bs2bPV3d1d92MIZwAAFNy6des0ffp0zZ07V9l3yaPZnnnmGU2fPn1cj3F3bdy4UevWrdO8efPqfhxtTQAACm7btm3aY489CGbBmJn22GOPcc9oEs4AAOgABLOYJrJfCGcAAACBcMwZAABoyMaNG3XcccdJkh5//HF1dXVpzz2zk9//5je/UU9Pz5iP7+vrU09Pj4466qia9znllFP0+OOP69Zbb23ewINi5gwAgMlmxQpp7lxpypTs54oVDa1ujz320J133qk777xTZ5xxhj784Q8PXd9RMJOycHbzzTfXvH3z5s1avXq1nnrqKT344IMNjXUs27dvb9m6x4NwBgDAZLJihbR0qfTQQ5J79nPp0oYD2kirV6/WMccco8MPP1xveMMb9Nhjj0mSLrjgAh100EE65JBDtHjxYq1du1Zf+9rX9IUvfEELFizQTTfdNGpd3/ve93TiiSdq8eLFWrly5dDyNWvW6HWve53mz5+vww47TA888IAk6bOf/awOPvhgzZ8/X2eddZYkadGiRUNf87hhwwaVv4/74osv1kknnaRjjz1Wxx13nLZs2aLjjjtOhx12mA4++GBdc801Q9u75JJLdMghh2j+/Pl6z3veo2eeeUbz5s1TqVSSJD399NPDrk8UbU0AADrJP/2TdOedtW+/9VbpueeGL9u6VXrf+6RvfKP6YxYskL74xbqH4O4688wzdc0112jPPffUFVdcoXPOOUfLly/XZz7zGf3pT3/STjvtpM2bN2vXXXfVGWecoV122UUf+9jHqq7v8ssv16c+9SnNmjVLb3vb23T22WdLkpYsWaKzzjpLb3nLW7Rt2zYNDg7qRz/6ka655hrddttt6u3t1ZNPPrnD8f72t7/VXXfdpd13313bt2/X97//fb3whS/Uhg0bdOSRR+qkk07Sfffdp3/7t3/TzTffrJkzZ+rJJ5/U9OnTtWjRIl133XU65ZRTtHLlSr31rW8d1znNqiGcAQAwmYwMZjtaPqFNPKe7775bxx9/vCRpYGBAe+21lyTpkEMO0ZIlS3TKKafolFNO2eG6/vznP+uPf/yjXv3qV8vM1N3drbvvvltz5szR+vXr9Za3vEVSdrJXSfr5z3+u008/Xb29vZKk3XfffYfbOP7444fu5+46++yzdeONN2rKlClav369/vznP+tXv/qV3v72t2vmzJnD1vv+979fn/vc53TKKafooosu0jdqBdxxIJwBANBJdjTDNXdu1socac4cqa+vKUNwd7385S/XLbfcMuq26667TjfeeKN+8IMf6Pzzz9fvf//7Mdd15ZVXatOmTUMncX366ad1+eWXD7Ur6zV16lQNDg5K0qjzjk2bNm3o9xUrVuiJJ57Q6tWr1d3drblz5455nrKjjz5aa9euVV9fnwYGBvSKV7xiXOOqhmPOAACYTM4/X8pnlYb09mbLm2SnnXbSE088MRTOSqWS7rnnHg0ODuqRRx7Ra1/7Wn32s5/VU089pS1btmj69Ol65plnqq7r8ssv149//GOtXbtWa9eu1erVq7Vy5UpNnz5ds2fP1tVXXy0pm63bunWrjj/+eF100UXaunWrJA21NefOnavVq1dLkq666qqaY3/qqaf0ohe9SN3d3brhhhv0UB5kjznmGH3nO9/Rxo0bh61Xkk477TS9613v0umnn97I0zaEcAYAwGSyZIm0bFk2U2aW/Vy2LFveJFOmTNFVV12lT3ziE5o/f74WLFigm2++WQMDA3r3u9+tgw8+WIceeqg+9KEPadddd9WJJ56o73//+6M+ELB27Vo99NBDOvLII4eWzZs3TzNmzNBtt92mSy+9VBdccIEOOeQQHXXUUXr88cd1wgkn6KSTTtLChQu1YMECff7zn5ckfexjH9OFF16oQw89VBs2bBjj6VmiVatW6eCDD9Yll1yiAw44QJJ04IEH6pxzztExxxyj+fPn6yMf+ciwx2zatEmnnnpqU54/c/emrCi1hQsXevlTGK3U19enRYsWtXw7GB/2S1zsm5jYL3FNZN/cd999OvDAA1szIEga+7s1r7rqKl1zzTW69NJLq95ebf+Y2Wp3X1jt/hxzBgAAMEFnnnmmfvSjH+n6669v2joJZwAAABP0pS99qenr5JgzAAA6QKccptRpJrJfCGcojmpfN5IvO+bYY0ctG/W1JGM8fkLLgEjG+VreYc20q45aUZeRxjOBMU5k3+y8caM2/va38lWrpLvukjZuzC533SVNZJnU2OPbsaxdY2yAu2vjxo1D52CrFx8IGCcOok2k/HUj+UejJUnd3dknjfr7x17W2yu9973St741scfXWmeTP93UqaiZNmikPlLWEWNs2nZKu++udWefrW0veUkW2hphJk2bJj37bPb1ThG1a4xm0h57SNOmadu2beMOWVJ2ctzZs2eP+taAsT4QQDgbJ95oEql10sSU5syR1q5NPYrwqJk2iFgfQKfI/61v9r9lY4Uz2poohocfTj2C0SKOCZMTr0WgdRLUF+EMxbDvvo09vqurOeOo1OiYgGZp12uxFXXUbIyxORjj8xL8W084QzFU+7qR7m6pp2fHy3p7s+NxJvr4Wuts4ledAA1ppD5S1hFjTD8exrjj7aT4t97dO+Jy+OGHezvccMMNbdkOqrjsMvfeXnfJfc6c7Ppll7nPmeODZqOWeeWy8uNHLh/Psp12Gr5t1IWaaZPLLnPv7q5aH9Ve3zusmVbVUauXdcAYJ7RveB5bux1v/r9lklZ5jUzDBwLGiYObE3vrW6U1a7KPOFdoy3459lhp+3bpxhtbu50OQ8200QEHSAsWSCtX7vCu7Je42Dcx8YEAoJb+/mzqOYXu7uEfXweiSVkfAJqGcIZiKZXShrNSKc22gXqkrA8ATUM4Q7EQzoDaCGdARyCcoVj6+0d/mqZdenpoayK2lPUBoGkIZygWZs6A2pg5AzoC4QzFQjgDaiOcAR2BcIZiKZXStjUJZ4gsZX0AaBrCGYqFU2kA1Q0MSIODzJwBHYBwhmKhrQlUV35tEs6AwiOcoVhoawLVlV+btDWBwiOcoVhoawLVlV+bzJwBhUc4Q7GkbmsODmYXIBramkDHIJyhWFK2NctverQ2ERFtTaBjEM5QLCnbmuU3PVqbiIi2JtAxCGcoltRtzfIYgGhoawIdg3CG4hgYkNwJZ0A1hDOgYxDOUBzltk3KU2lIhDPElLo+ADQN4QzFkXpmoLxdjjlDRKnrA0DTEM5QHKnffGhrIrLU9QGgaQhnKI7UpwqgrYnIUtcHgKYhnKE4Up8qgLYmIktdHwCahnCG4kjdtqGtichS1weApiGcoThSt21oayKy1PUBoGkIZyiO1G0b2pqILHV9AGgawhmKI3XbhrYmIktdHwCahnCG4kjdtiGcIbLU9QGgaQhnKI7UbRu++ByRpa4PAE1DOENxpG7bMHOGyFLXB4CmIZyhOFK3bQhniCx1fQBoGsIZiiN124ZTaSCy1PUBoGkIZyiO1G0bTqWByFLXB4CmIZyhOFK/+dDWRGTl12VXV9pxAGgY4QzFUZ6x4hsCgNH6+7PXqFnqkQBoEOEMxRFl5oy2JiIqlWhpAh2CcIbiiBLOmDlDRIQzoGMQzlAcqU8VMHXq8HEAkZRKnEYD6BCEMxRH6lMFmGXbpq2JiPr7mTkDOgThDMWRuq1Z3jYzZ4iItibQMQhnKI7UbU2JcIa4aGsCHYNwhuLo789aiynP49TTQzhDTLQ1gY5BOENxRGjbcMwZoopQHwCaoqXhzMxOMLP7zWyNmZ1V5fZ9zewGM7vDzO4yszfly+ea2V/N7M788rVWjhMFEaFtQ1sTUUWoDwBNMbVVKzazLklfkXS8pHWSbjeza9393oq7/bOkK939QjM7SNL1kubmtz3g7gtaNT4UUIS2DW1NRBWhPgA0RStnzo6QtMbdH3T3fkkrJZ084j4u6YX57zMkPdrC8aDoIrRtaGsiqgj1AaApWjZzJmlvSY9UXF8n6ZUj7nOupJ+a2ZmSpkl6XcVt88zsDklPS/pnd79p5AbMbKmkpZI0a9Ys9fX1NW3wtWzZsqUt28FoL3v4Ye0+OKhbqjz/7dovC597Ttsee0x38xqoGzXTHodu3KiB3l7dVedzzX6Ji30TUzv3SyvDWT1OlXSxu/+7mb1K0qVm9gpJj0na1903mtnhkq42s5e7+9OVD3b3ZZKWSdLChQt90aJFLR9wX1+f2rEdVPHNb0rTp1d9/tu2X3bfXbvMmMFrYByomTbZeWdp1qy6n2v2S1zsm5jauV9a2dZcL2mfiuuz82WV3ifpSkly91sk7Sxpprs/5+4b8+WrJT0g6aUtHCuKIELbhrYmoopQHwCaopXh7HZJ+5vZPDPrkbRY0rUj7vOwpOMkycwOVBbOnjCzPfMPFMjM9pO0v6QHWzhWFEGENx8+rYmoItQHgKZoWVvT3beb2Qcl/URSl6Tl7n6PmZ0naZW7Xyvpo5K+YWYfVvbhgL9zdzez10g6z8xKkgYlneHuT7ZqrCiICKcK6O6Wnn027RiAaiLUB4CmaOkxZ+5+vbLTY1Qu+1TF7/dKOrrK474r6butHBsKKMKpAnp6pE2b0o4BqCZCfQBoCr4hAMURoW1DWxNRRagPAE1BOENxRGjbEM4QVYT6ANAUhDMUR4S2Dd8QgKgi1AeApiCcoTgitG04lQaiilAfAJqCcIbiiNC2oa2JqCLUB4CmIJyhOCK0bWhrIqLBQWlgIH19AGgKwhmKI0LbhrYmIir/hyF1fQBoCsIZiiNKOGPmDNEQzoCOQjhDcfT3pz+mhrYmIirP5qauDwBNQThDcUSZOdu+XXJPOw6gEjNnQEchnKE4ooSz8liAKAhnQEchnKE4IpwqgHCGiMqvx9T1AaApCGcojiin0iiPBYii/HpMXR8AmoJwhmIYHMwuqd98mDlDRLQ1gY5COEMxRGnbEM4QUZT6ANAUhDMUQ5S2TfnNj3CGSKLUB4CmIJyhGKK0bcrb55gzRBKlPgA0BeEMxRClbUNbExFFqQ8ATUE4QzFEadvQ1kREUeoDQFMQzlAMUdo2tDURUZT6ANAUhDMUQ5S2DW1NRBSlPgA0BeEMxRClbUNbExFFqQ8ATUE4QzFEadvQ1kREUeoDQFMQzlAMUd58aGsioij1AaApCGcohvJMVepjaghniChKfQBoCsIZiiHKzADHnCGiKPUBoCkIZyiGKG8+HHOGiKLUB4CmIJyhGKKcKoC2JiKKUh8AmoJwhmKIcqoA2pqIKEp9AGgKwhmKIUrbhrYmIirXx9SpaccBoCkIZyiGKG0b2pqIqFTKXptmqUcCoAkIZyiGKG0b2pqIqL8/fW0AaBrCGYqBtiZQW3nmDEBHIJyhGGhrArWVSulrA0DTEM5QDFHammZSVxfhDLHQ1gQ6CuEMxRClrSllMxS0NREJbU2goxDOUAyRwll3NzNniIVwBnQUwhmKoTxTFeE8ToQzRNPfzzFnQAchnKEYIp3HqaeHcIZYmDkDOgrhDMUQ6c2nu5tjzhBLpPoA0DDCGYoh0qkCaGsimkj1AaBhhDMUQ6RTBdDWRDSR6gNAwwhnKIZIbRvamogmUn0AaBjhDMUQqW1DWxPRRKoPAA0jnKEYIrVtaGsimkj1AaBhhDMUQ6S2DW1NRBOpPgA0jHCGYojUtqGtiWgi1QeAhhHOUAyR2jaEM0QTqT4ANIxwhmKI1Lbhi88RTaT6ANAwwhmKIdKbDzNniCZSfQBoGOEMxRDpi50JZ4gmUn0AaBjhDMUQaWaAU2kgmkj1AaBhhDMUQ6Q3H06lgWgi1QeAhhHOUAyRThVAWxORuEvbt8epDwANI5yhGCKdKoC2JiIpvxaj1AeAhhHOUAyR2ja0NREJ4QzoOIQzFANtTaC68msxSn0AaBjhDMUQsa3pnnokwPOzuFHqA0DDCGcohmhtTSk7CBtIjbYm0HEIZyiGaG1NidYmYqCtCXQcwhmKIVJbk3CGSGhrAh2HcIb43KWBgThvPuUZCsIZIqCtCXQcwhnii9a2Kb8JcjoNRBCtPgA0jHCG+KK1bWhrIpJo9QGgYYQzxBetbUNbE5FEqw8ADSOcIb5obz60NRFJtPoA0DDCGeKLdkwNbU1EEq0+ADSMcIb4oh1TQ1sTkUSrDwANI5whvmhtG9qaiCRafQBoGOEM8UVr29DWRCTR6gNAwwhniC9a24Zwhkii1QeAhhHOEF+0tk15hoK2JiKIVh8AGkY4Q3zR2jbMnCGSaPUBoGGEM8QXrW1DOEMk0eoDQMMIZ4gvWtuGU2kgkmj1AaBhhDPEF61tw6k0EEm0+gDQMMIZ4ovWtqGtiUii1QeAhhHOEF+0tg1tTUQSrT4ANIxwhviivfnQ1kQkpZLU1SWZpR4JgCYhnCG+cgiKckwNbU1E0t8fpzYANAXhDPFFmzmjrYlISqU4tQGgKQhniC9aOKOtiUgIZ0DHIZwhvminCpgyJbswc4YISqU4tQGgKQhniC/iqQK6uwlniKG/P1ZtAGgY4QzxRWtrStlMBW1NREBbE+g4hDPEFzGcMXOGKGhrAh2HcIb4+vulqVNjnceJcIYoaGsCHYdwhvgitm16eghniCFifQBoCOEM8UVs23R3c8wZYohYHwAaQjhDfBHbNrQ1EUXE+gDQkJaGMzM7wczuN7M1ZnZWldv3NbMbzOwOM7vLzN5Ucdsn88fdb2ZvaOU4EVzEtg1tTUQRsT4ANKRl4czMuiR9RdIbJR0k6VQzO2jE3f5Z0pXufqikxZK+mj/2oPz6yyWdIOmr+fowGUV886GtiSgi1geAhrRy5uwISWvc/UF375e0UtLJI+7jkl6Y/z5D0qP57ydLWunuz7n7nyStydeHySjiFzvT1kQUEesDQEOmtnDde0t6pOL6OkmvHHGfcyX91MzOlDRN0usqHnvriMfuPXIDZrZU0lJJmjVrlvr6+pox7jFt2bKlLdvB8w569FFNK5V0+xjPe7v3y4KtW+X9/fodr4UdomZa679t3qytM2bonnE+x+yXuNg3MbVzv7QynNXjVEkXu/u/m9mrJF1qZq+o98HuvkzSMklauHChL1q0qDWjrNDX16d2bAcVdt1VmjFjzOe97ftlzz2l557jtVAHaqbFeno07cUvHvdzzH6Ji30TUzv3Syvbmusl7VNxfXa+rNL7JF0pSe5+i6SdJc2s87GYLCKeKoC2JqKIWB8AGtLKcHa7pP3NbJ6Z9Sg7wP/aEfd5WNJxkmRmByoLZ0/k91tsZjuZ2TxJ+0v6TQvHisginiqAcIYoItYHgIa0rK3p7tvN7IOSfiKpS9Jyd7/HzM6TtMrdr5X0UUnfMLMPK/twwN+5u0u6x8yulHSvpO2S/sHdB1o1VgQX8dNonEoDUUSsDwANaekxZ+5+vaTrRyz7VMXv90o6usZjz5d0fivHh4IolaTe3tSjGI5TaSAK2ppAx+EbAhBfxLYNbU1EEbE+ADSEcIb4IrZtaGsiioj1AaAhhDPEF7FtQ1sTEbjHrA8ADSGcIb6IbRvamohg+/bsZ7T6ANAQwhnii9i2oa2JCMqvwWj1AaAhhDPEFzGc0dZEBIQzoCMRzhBfxC92pq2JCMr/QYhWHwAaQjhDfFFnztylAc6NjISYOQM6EuEM8UUMZ+WZClqbSIlwBnQkwhnii3iqgPKbIa1NpFR+/UWrDwANIZwhtvJ5nKLNDBDOEEF55jZafQBoCOEMsUU9j1N5poJwhpRoawIdiXCG2KK2bcpvhhxzhpSi1geAhhDOEFvUtg1tTUQQtT4ANIRwhtiitm1oayKCqPUBoCGEM8QWtW1DWxMRRK0PAA0hnKPvStAAAB7vSURBVCG2qG0b2pqIIGp9AGgI4QyxRW3b0NZEBFHrA0BDCGeILWrbhrYmIohaHwAaQjhDbFHbNrQ1EUHU+gDQEMIZYovatiGcIYKo9QGgIYQzxBb1zYdjzhBB1PoA0BDCGWIrt22iHVPDMWeIIGp9AGgI4QyxRZ0ZoK2JCKLWB4CGEM4QW9Q3H9qaiCBqfQBoCOEMsUU9VQBtTUQQtT4ANIRwhtiiniqAtiYiiFofABpCOENsUds2tDURQakkTZmSXQB0DCoasUVt29DWRASlUrzaANAwwhlii9q2oa2JCPr749UGgIYRzhBb1LYm4QwRlErxagNAwwhniC1qW7OrSzKjrYm0aGsCHYlwhtiitjXNsjExc4aUaGsCHYlwhtiitjUlwhnSo60JdCTCGWKLHM56eghnSItwBnQkwhli6+/Pju+KeB6n7m6OOUNa/f0ccwZ0oIDveECFyDMDtDWRWuT6ADBhhDPEFvnNh7YmUotcHwAmjHCG2CKfKoC2JlKLXB8AJoxwhtginyqAtiZSi1wfACaMcIbYIrdtaGsitcj1AWDCCGeILXLbhrYmUotcHwAmjHCG2CK3bWhrIrXI9QFgwghniC1y24ZwhtQi1weACSOcIbbIbZueHtqaSCtyfQCYMMIZYovctmHmDKlFrg8AE0Y4Q2yR2zaEM6QWuT4ATBjhDLFFfvPhVBpILXJ9AJgwwhlii/zFzpxKA6lFrg8AE0Y4Q2yRZwZoayK1yPUBYMIIZ4gt8psPbU2kFrk+AEwY4QyxRT5VAG1NpDQwILnHrQ8AE0Y4Q2yRTxVAWxMplf9jELU+AEwY4QyxRW7b0NZESuXXXtT6ADBhhDPERlsTqK4czqLWB4AJI5whtuhtzcHB7AK0G21NoGMRzhBb5LZmeVy0NpECbU2gYxHOEFvktmZ5XIQzpEBbE+hYhDPE5R6/rSlx3BnSoK0JdCzCGeIaGMh+Rn3zoa2JlGhrAh2LcIa4ordtaGsipej1AWDCCGeIK3rbhrYmUopeHwAmjHCGuKK3bWhrIqXo9QFgwghniCv6mw9tTaQUvT4ATBjhDHGV2zZRj6mhrYmUotcHgAkjnCGu6DMDtDWRUvT6ADBhhDPEFf3Nh3CGlKLXB4AJI5whruinCiiPi7YmUoheHwAmjHCGuKKfKoCZM6QUvT4ATBjhDHFFb9sQzpBS9PoAMGGEM8QVvW3DqTSQUvT6ADBhhDPEFb1tw6k0kFL0+gAwYYQzxBW9bUNbEylFrw8AE7bDcGZmJ5oZIQ7tF71tQ1sTKUWvDwATVk/oeqekP5rZ58zsgFYPCBgSvW1DWxMpRa8PABO2w3Dm7u+WdKikByRdbGa3mNlSM5ve8tFhcovetqGtiZRKJclM6upKPRIATVZXu9Ldn5Z0laSVkvaS9BZJvzWzM1s4Nkx20cMZbU2kVCrFrQ0ADannmLOTzOz7kvokdUs6wt3fKGm+pI+2dniY1KJ/sTNtTaTU3x+3NgA0ZGod93mbpC+4+42VC919q5m9rzXDAhR/5oy2JlJi5gzoWPWEs3MlPVa+YmYvkDTL3de6+y9aNTAgfDibmpcP4QwpEM6AjlXPMWffkTRYcX0gXwa0VvRTBZhlb460NZFCqRS3NgA0pJ5wNtXdh9598t/5FwGtV4RTBXR3M3OGNPr7Y9cGgAmrJ5w9YWYnla+Y2cmSNrRuSEAueltTIpwhHdqaQMeq55izMyStMLMvSzJJj0g6raWjAqTszWfKlNjncerpIZwhDdqaQMfaYThz9wckHWlmu+TXt7R8VIBUjLYNx5whlSLUB4AJqWfmTGb2PyS9XNLOZiZJcvfzWjguoBhtG9qaSKUI9QFgQuo5Ce3XlH2/5pnK2ppvlzSnxeMCitG2oa2JVIpQHwAmpJ4PBBzl7qdJ2uTun5b0Kkkvbe2wABWjbUNbE6kUoT4ATEg94Wxb/nOrmb1YUknZ92sCrVWEtg1tTaRShPoAMCH1HHP2AzPbVdL/kfRbSS7pGy0dFSAV482HtiZSKUJ9AJiQMWfOzGyKpF+4+2Z3/66yY80OcPdP1bNyMzvBzO43szVmdlaV279gZnfml/8ys80Vtw1U3HbtOP8uFMmKFdLcudlpM+bOza6vWCF973vSn/70/LJoVqyQ7rpL+tGPho+72t9Sz7LyOif6+HYsm8AYjzn22PBjLMLzOGrZ738vXXdd3PoAMHHuPuZF0h07uk+Nx3VJekDSfsq+UeB3kg4a4/5nSlpecX3LeLZ3+OGHezvccMMNbdnOpHHZZe69ve7S85fubveenuHLenuz+9bQ9v1S77jrXdbb6/6BDzR3nc1exhjjjnEH9VEN/5bFxb6Jqdn7RdIqr5Fp6jnm7Bdm9jYrn0OjfkdIWuPuD3r2lU8rJZ08xv1PlXT5OLeBojvnHGnr1uHLSqXRB9lv3ZrdN4p6x13vsq1bpQsvbO46m72MMcYdY7T6ANAQy8LbGHcwe0bSNEnblX04wCS5u79wB4/7W0knuPv78+vvkfRKd/9glfvOkXSrpNnuPpAv2y7pzny7n3H3q6s8bqmkpZI0a9asw1euXDn2X9sEW7Zs0S677NLy7UwWxxx7rGwHr8EyN9OvfvnLqre1e7+MZ9z1cmXFFRljbI5WjHGs+qiGf8viYt/E1Oz98trXvna1uy+sdls93xAwvWkjqW2xpKvKwSw3x93Xm9l+kn5pZr/37NsKKse2TNIySVq4cKEvWrSo5QPt6+tTO7Yzaey7r/TQQ3Xd1fbdt+Zz3/b9Mo5x18u6uqSBgR3fMSHG2BytGONY9VEN/5bFxb6JqZ37pZ6T0L6m2qWOda+XtE/F9dn5smoWa0RL093X5z8flNQn6dA6tomiOf98qbd3+LLu7tEn1+ztze4bRb3jrndZb6+0dGlz19nsZYwx7hij1QeAhtRzzNnHKy7/IukHks6t43G3S9rfzOaZWY+yADbqU5dmdoCk3STdUrFsNzPbKf99pqSjJd1bxzZRNEuWSMuWZZ9Ek6Q5c6SLLpKWL89+N8t+LluW3TeK8rgrx1ht3PUuW7ZM+upXm7vOZi+b4Bi9AGMswvO4w3VGqg8ADdnhMWejHmC2j6Qvuvvb6rjvmyR9UdknN5e7+/lmdp6yTyhcm9/nXEk7u/tZFY87StLXJQ0qC5BfdPdvjrWthQsX+qpVq8b1t0wE080tssce0qmnSl/+8oQezn6Ji30TE/slLvZNTM3eL2Y28WPOqlgn6cB67uju10u6fsSyT424fm6Vx90s6eAJjA1FxQk1AQCQVEc4M7MvKftwkZTNYi1Q9k0BQPPwJc4AAEiqb+assle4XdLl7v7rFo0HkxVf4gwAgKT6wtlVkrZVnH+sy8x63X3rDh4H1GdwMLsQzgAAqO8bAiS9oOL6CyT9vDXDwaRU/uJw2poAANQVznZ29y3lK/nvvWPcHxif8lfRMHMGAEBd4exZMzusfMXMDpf019YNCZNOeeaMcAYAQF3HnP2TpO+Y2aPKvg7ubyS9s6WjwuRCWxMAgCH1fLfm7flZ/F+WL7rf3UutHRYmFdqaAAAMqee7Nf9B0jR3v9vd75a0i5n9r9YPDZMGbU0AAIbUc8zZ37v75vIVd98k6e9bNyRMOoQzAACG1BPOuszMylfMrEsSBwehecptTY45AwCgrg8E/FjSFWb29fz6/5T0o9YNCZMOM2cAAAypJ5x9QtJSSWfk1+9S9olNoDkIZwAADNlhW9PdByXdJmmtpCMkHSvpvtYOC5MKp9IAAGBIzZkzM3uppFPzywZJV0iSu7+2PUPDpMGpNAAAGDJWW/MPkm6S9GZ3XyNJZvbhtowKkwttTQAAhozV1nyrpMck3WBm3zCz45R9QwDQXLQ1AQAYUjOcufvV7r5Y0gGSblD2NU4vMrMLzez17RogJgHamgAADKnnAwHPuvu33f1ESbMl3aHsE5xAc9DWBABgSD0noR3i7pvcfZm7H9eqAWESoq0JAMCQcYUzoCVoawIAMIRwhvRoawIAMIRwhvQIZwAADCGcIT2++BwAgCGEM6THzBkAAEMIZ0iPcAYAwBDCGdIrh7OpY32bGAAAkwPhDOn192ezZsa3gwEAQDhDeqUSLU0AAHKEM6RXKvFJTQAAcoQzpFduawIAAMIZAqCtCQDAEMIZ0qOtCQDAEMIZ0qOtCQDAEMIZ0qOtCQDAEMIZ0qOtCQDAEMIZ0qOtCQDAEMIZ0qOtCQDAEMIZ0iOcAQAwhHCG9Pr7OeYMAIAc4QzpMXMGAMAQwhnSI5wBADCEcIb0OJUGAABDCGdIj1NpAAAwhHCG9GhrAgAwhHCG9GhrAgAwhHCG9GhrAgAwhHCG9GhrAgAwhHCG9GhrAgAwhHCG9GhrAgAwhHCGtNylgQHCGQAAOcIZ0iqVsp+EMwAAJBHOkFp/f/aTY84AAJBEOENqzJwBADAM4QxpEc4AABiGcIa0yuGMtiYAAJIIZ0itfMwZM2cAAEginCE12poAAAxDOENatDUBABiGcIa0aGsCADAM4Qxp0dYEAGAYwhnSoq0JAMAwhDOkRVsTAIBhCGdIi7YmAADDEM6QFuEMAIBhCGdIiy8+BwBgGMIZ0mLmDACAYQhnSItwBgDAMIQzpMWpNAAAGIZwhrQ4lQYAAMMQzpAWbU0AAIYhnCEt2poAAAxDOENatDUBABiGcIa0aGsCADAM4QxpEc4AABiGcIa0+vulqVMls9QjAQAgBMIZ0iqVmDUDAKAC4QxplUp8UhMAgAqEM6TV38/MGQAAFQhnSIu2JgAAwxDOkBbhDACAYQhnSKu/n2POAACoQDhDWsycAQAwDOEMaRHOAAAYhnCGtDiVBgAAwxDOkBan0gAAYBjCGdKirQkAwDCEM6RFWxMAgGEIZ0iLtiYAAMMQzpAWbU0AAIZpaTgzsxPM7H4zW2NmZ1W5/Qtmdmd++S8z21xx23vN7I/55b2tHCcSoq0JAMAwU1u1YjPrkvQVScdLWifpdjO71t3vLd/H3T9ccf8zJR2a/767pH+VtFCSS1qdP3ZTq8aLRGhrAgAwTCtnzo6QtMbdH3T3fkkrJZ08xv1PlXR5/vsbJP3M3Z/MA9nPJJ3QwrEiFdqaAAAM07KZM0l7S3qk4vo6Sa+sdkczmyNpnqRfjvHYvas8bqmkpZI0a9Ys9fX1NTzoHdmyZUtbtjNZvOrZZ/Xkhg26v8HnlP0SF/smJvZLXOybmNq5X1oZzsZjsaSr3H1gPA9y92WSlknSwoULfdGiRS0Y2nB9fX1qx3Ymk73mzNFeDT6n7Je42DcxsV/iYt/E1M790sq25npJ+1Rcn50vq2axnm9pjvexKDLamgAADNPKcHa7pP3NbJ6Z9SgLYNeOvJOZHSBpN0m3VCz+iaTXm9luZrabpNfny9BpCGcAAAzTsramu283sw8qC1Vdkpa7+z1mdp6kVe5eDmqLJa10d6947JNm9r+VBTxJOs/dn2zVWJEQp9IAAGCYlh5z5u7XS7p+xLJPjbh+bo3HLpe0vGWDQ3ruzJwBADAC3xCAdLZvz34SzgAAGEI4QzqlUvaTtiYAAEMIZ0invz/7ycwZAABDCGdIpzxzRjgDAGAI4Qzp0NYEAGAUwhnSoa0JAMAohDOkQ1sTAIBRCGdIh3AGAMAohDOkU25rcswZAABDCGdIh5kzAABGIZwhHcIZAACjEM6QDqfSAABgFMIZ0uFUGgAAjEI4Qzq0NQEAGIVwhnRoawIAMArhDOnQ1gQAYBTCGdKhrQkAwCiEM6RDWxMAgFEIZ0iHtiYAAKMQzpAObU0AAEYhnCEd2poAAIxCOEM6tDUBABiFcIZ0aGsCADAK4QzpEM4AABiFcIZ0SiWpq0uawssQAIAy3hWRTn8/s2YAAIxAOEM6pRLhDACAEQhnSKdU4jQaAACMQDhDOrQ1AQAYhXCGdGhrAgAwCuEM6dDWBABgFMIZ0qGtCQDAKIQzpENbEwCAUQhnSIe2JgAAoxDOkA5tTQAARiGcIR3amgAAjEI4QzqEMwAARiGcIZ3+fo45AwBgBMIZ0mHmDACAUQhnSIdwBgDAKIQzpMOpNAAAGIVwhnQ4lQYAAKMQzpAObU0AAEYhnCEd2poAAIxCOEM6tDUBABiFcIZ0aGsCADAK4Qzp0NYEAGAUwhnScKetCQBAFYQzpDEwkP0knAEAMAzhDGmUStlPwhkAAMMQzpBGf3/2k2POAAAYhnCGNJg5AwCgKsIZ0iCcAQBQFeEMaZTDGW1NAACGIZwhjfIxZ8ycAQAwDOEMadDWBACgKsIZ0qCtCQBAVYQzpEFbEwCAqghnSIO2JgAAVRHOkAZtTQAAqiKcIQ3amgAAVEU4Qxq0NQEAqIpwhjQIZwAAVEU4Qxp88TkAAFURzpAGM2cAAFRFOEMahDMAAKoinCENTqUBAEBVhDOkwak0AACoinCGNGhrAgBQFeEMadDWBACgKsIZ0qCtCQBAVYQzpEFbEwCAqghnSKNUkqZMkbq6Uo8EAIBQCGdIo7+fWTMAAKognCGNUolwBgBAFYQzpFEq8UlNAACqIJwhDdqaAABURThDGrQ1AQCoinCGNAhnAABURThDGv39HHMGAEAVhDOkwcwZAABVEc6QBuEMAICqCGdIg1NpAABQFeEMaXAqDQAAqiKcIQ3amgAAVEU4Qxq0NQEAqIpwhjRoawIAUBXhDGnQ1gQAoCrCGdKgrQkAQFWEM6RBWxMAgKpaGs7M7AQzu9/M1pjZWTXu8w4zu9fM7jGzb1csHzCzO/PLta0cJxKgrQkAQFVTW7ViM+uS9BVJx0taJ+l2M7vW3e+tuM/+kj4p6Wh332RmL6pYxV/dfUGrxofECGcAAFTVypmzIyStcfcH3b1f0kpJJ4+4z99L+oq7b5Ikd/9LC8eDSPjicwAAqmrZzJmkvSU9UnF9naRXjrjPSyXJzH4tqUvSue7+4/y2nc1slaTtkj7j7leP3ICZLZW0VJJmzZqlvr6+pv4B1WzZsqUt2+l0r962TY89/rgeaNJzyX6Ji30TE/slLvZNTO3cL60MZ/Vuf39JiyTNlnSjmR3s7pslzXH39Wa2n6Rfmtnv3f2Byge7+zJJyyRp4cKFvmjRopYPuK+vT+3YTscbHNQ+++2nfZr0XLJf4mLfxMR+iYt9E1M790sr25rrJe1TcX12vqzSOknXunvJ3f8k6b+UhTW5+/r854OS+iQd2sKxot04lQYAAFW1MpzdLml/M5tnZj2SFksa+anLq5XNmsnMZiprcz5oZruZ2U4Vy4+WdK/QGQYGpMFBPhAAAEAVLWtruvt2M/ugpJ8oO55subvfY2bnSVrl7tfmt73ezO6VNCDp4+6+0cyOkvR1MxtUFiA/U/kpTxRcqZT9JJwBADBKS485c/frJV0/YtmnKn53SR/JL5X3uVnSwa0cGxIqhzPamgAAjMI3BKD9+vuzn8ycAQAwCuEM7UdbEwCAmghnaD/amgAA1EQ4Q/vR1gQAoCbCGdqPtiYAADURztB+hDMAAGoinKH9ym1NjjkDAGAUwhnaj5kzAABqIpyh/QhnAADURDhD+3EqDQAAaiKcof04lQYAADURztB+tDUBAKiJcIb2o60JAEBNhDO0H21NAABqIpyh/WhrAgBQE+EM7UdbEwCAmghnaD/amgAA1EQ4Q/vR1gQAoCbCGdqPtiYAADURztB+tDUBAKiJcIb2o60JAEBNhDO0XzmcdXWlHQcAAAERztB+/f3Z8WZmqUcCAEA4hDO0X6lESxMAgBoIZ2g/whkAADURztB+pRKn0QAAoAbCGdqvv5+ZMwAAaiCcof1oawIAUBPhDO1HWxMAgJoIZ2g/2poAANREOEP70dYEAKAmwhnaj7YmAAA1Ec7QfrQ1AQCoiXCG9qOtCQBATYQztB/hDACAmghnaL/yF58DAIBRCGdoP2bOAACoiXCG9iOcAQBQE+EM7cepNAAAqIlwhvbjVBoAANREOKvXihXS3Lk65thjpblzs+v5Mk2Z0rplFdtu6XbaOcb166WLLx7+eAAAIEkyd089hqZYuHChr1q1qjUrX7FCWrpU2rr1+WXd3ZJZNgvUqmW9vdJ73yt961vt33a7xtjbKy1bJi1Zokb09fVp0aJFDa0DrcG+iYn9Ehf7JqZm7xczW+3uC6vdNrVpW+lk55wzPHhI2XFTIzV72dat0te+Jo0M0O3YdrvGuHVr9vw2GM4AAOgUtDXr8fDD6bZdhJnNRseY8vkFACAYwlk99t033ba7utJtu16NjjHl8wsAQDCEs3qcf352bFSl7u7Rp4No9rLe3uxYtxTbbtcYe3uz5xcAAEginNVnyZLsoPU5c+Rm0pw50kUXScuXZ7+3atmyZdJXvzq07ZZtJ+UYm/BhAAAAOgmf1hwnPkUTE/slLvZNTOyXuNg3MbXz05rMnAEAAARCOAMAAAiEcAYAABAI4QwAACAQwhkAAEAghDMAAIBACGcAAACBEM4AAAACIZwBAAAEQjgDAAAIhHAGAAAQCOEMAAAgEMIZAABAIIQzAACAQAhnAAAAgRDOAAAAAiGcAQAABEI4AwAACIRwBgAAEAjhDAAAIBBz99RjaAoze0LSQ23Y1ExJG9qwHYwP+yUu9k1M7Je42DcxNXu/zHH3Pavd0DHhrF3MbJW7L0w9DgzHfomLfRMT+yUu9k1M7dwvtDUBAAACIZwBAAAEQjgbv2WpB4Cq2C9xsW9iYr/Exb6JqW37hWPOAAAAAmHmDAAAIBDCGQAAQCCEszqZ2Qlmdr+ZrTGzs1KPZzIzs33M7AYzu9fM7jGzf8yX725mPzOzP+Y/d0s91snIzLrM7A4z+2F+fZ6Z3ZbXzhVm1pN6jJORme1qZleZ2R/M7D4zexU1k56ZfTj/d+xuM7vczHamZtIws+Vm9hczu7tiWdUascwF+T66y8wOa+ZYCGd1MLMuSV+R9EZJB0k61cwOSjuqSW27pI+6+0GSjpT0D/n+OEvSL9x9f0m/yK+j/f5R0n0V1z8r6Qvu/hJJmyS9L8mo8B+SfuzuB0iar2wfUTMJmdnekj4kaaG7v0JSl6TFomZSuVjSCSOW1aqRN0raP78slXRhMwdCOKvPEZLWuPuD7t4vaaWkkxOPadJy98fc/bf5788oe5PZW9k++VZ+t29JOiXNCCcvM5st6X9I+s/8ukk6VtJV+V3YLwmY2QxJr5H0TUly93533yxqJoKpkl5gZlMl9Up6TNRMEu5+o6QnRyyuVSMnS7rEM7dK2tXM9mrWWAhn9dlb0iMV19fly5CYmc2VdKik2yTNcvfH8pselzQr0bAmsy9K+r8lDebX95C02d2359epnTTmSXpC0kV5y/k/zWyaqJmk3H29pM9LelhZKHtK0mpRM5HUqpGW5gLCGQrLzHaR9F1J/+TuT1fe5tk5YjhPTBuZ2Zsl/cXdV6ceC0aZKukwSRe6+6GSntWIFiY103758UsnKwvPL5Y0TaPbagiinTVCOKvPekn7VFyfnS9DImbWrSyYrXD37+WL/1yeVs5//iXV+CapoyWdZGZrlbX+j1V2nNOuectGonZSWSdpnbvfll+/SllYo2bSep2kP7n7E+5ekvQ9ZXVEzcRRq0ZamgsIZ/W5XdL++SdoepQdsHlt4jFNWvlxTN+UdJ+7/78VN10r6b357++VdE27xzaZufsn3X22u89VViO/dPclkm6Q9Lf53dgvCbj745IeMbOX5YuOk3SvqJnUHpZ0pJn15v+ulfcLNRNHrRq5VtJp+ac2j5T0VEX7s2F8Q0CdzOxNyo6n6ZK03N3PTzykScvMXi3pJkm/1/PHNp2t7LizKyXtK+khSe9w95EHd6INzGyRpI+5+5vNbD9lM2m7S7pD0rvd/bmU45uMzGyBsg9q9Eh6UNLpyv6DTs0kZGaflvROZZ9Cv0PS+5Udu0TNtJmZXS5pkaSZkv4s6V8lXa0qNZKH6S8ra0NvlXS6u69q2lgIZwAAAHHQ1gQAAAiEcAYAABAI4QwAACAQwhkAAEAghDMAAIBACGcAJgUzGzCzOysuTfuSbzOba2Z3N2t9ACa3qTu+CwB0hL+6+4LUgwCAHWHmDMCkZmZrzexzZvZ7M/uNmb0kXz7XzH5pZneZ2S/MbN98+Swz+76Z/S6/HJWvqsvMvmFm95jZT83sBcn+KACFRjgDMFm8YERb850Vtz3l7gcrO+P3F/NlX5L0LXc/RNIKSRfkyy+Q9Ct3n6/s+ynvyZfvL+kr7v5ySZslva3Ffw+ADsU3BACYFMxsi7vvUmX5WknHuvuDZtYt6XF338PMNkjay91L+fLH3H2mmT0haXbl1+mY2VxJP3P3/fPrn5DU7e7/1vq/DECnYeYMACSv8ft4VH734YA4phfABBHOACD74unyz1vy32+WtDj/fYmkm/LffyHpA5JkZl1mNqNdgwQwOfA/OwCTxQvM7M6K6z929/LpNHYzs7uUzX6dmi87U9JFZvZxSU9IOj1f/o+SlpnZ+5TNkH1A0mMtHz2ASYNjzgBMavkxZwvdfUPqsQCARFsTAAAgFGbOAAAAAmHmDAAAIBDCGQAAQCCEMwAAgEAIZwAAAIEQzgAAAAL5/wEn8zH+XWcEEgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}